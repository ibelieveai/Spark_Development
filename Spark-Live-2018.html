<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>Spark-Live-2018 - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta name="robots" content="nofollow">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/img/favicon.ico"/>
<script>window.settings = {"enableUsageDeliveryConfiguration":false,"enableNotebookNotifications":true,"enableSshKeyUI":false,"defaultInteractivePricePerDBU":0.4,"enableClusterMetricsUI":true,"allowWhitelistedIframeDomains":true,"enableOnDemandClusterType":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","enableJobsPrefetching":true,"workspaceFeaturedLinks":[{"linkURI":"https://docs.databricks.com/index.html","displayName":"Documentation","icon":"question"},{"linkURI":"https://docs.databricks.com/release-notes/product/index.html","displayName":"Release Notes","icon":"code"},{"linkURI":"https://docs.databricks.com/spark/latest/training/index.html","displayName":"Training & Tutorials","icon":"graduation-cap"}],"enableReservoirTableUI":true,"enableClearStateFeature":true,"dbcForumURL":"http://forums.databricks.com/","enableProtoClusterInfoDeltaPublisher":true,"enableAttachExistingCluster":true,"resetJobListOnConnect":true,"serverlessDefaultSparkVersion":"latest-stable-scala2.11","maxCustomTags":45,"serverlessDefaultMaxWorkers":20,"enableInstanceProfilesUIInJobs":true,"nodeInfo":{"node_types":[{"support_ssh":false,"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":8.0,"node_type_id":"dev-tier-node","description":"Community Optimized","support_cluster_tags":false,"container_memory_mb":6000,"node_instance_type":{"instance_type_id":"r3.2xlarge","provider":"AWS","local_disk_size_gb":160,"compute_units":26.0,"number_of_ips":14,"local_disks":1,"reserved_compute_units":3.64,"gpus":0,"memory_mb":62464,"num_cores":8,"local_disk_type":"AHCI","max_attachable_disks":0,"supported_disk_types":[{"ebs_volume_type":"GENERAL_PURPOSE_SSD"},{"ebs_volume_type":"THROUGHPUT_OPTIMIZED_HDD"}],"reserved_memory_mb":4800},"memory_mb":6144,"is_hidden":false,"category":"Community Edition","num_cores":0.88,"support_port_forwarding":false,"support_ebs_volumes":false,"is_deprecated":false}],"default_node_type_id":"dev-tier-node"},"sqlAclsDisabledMap":{"spark.databricks.acl.enabled":"false","spark.databricks.acl.sqlOnly":"false"},"enableDatabaseSupportClusterChoice":true,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":999999,"serverlessClusterProductName":"Serverless Pool","showS3TableImportOption":true,"maxEbsVolumesPerInstance":10,"enableRStudioUI":false,"isAdmin":true,"deltaProcessingBatchSize":1000,"timerUpdateQueueLength":100,"sqlAclsEnabledMap":{"spark.databricks.acl.enabled":"true","spark.databricks.acl.sqlOnly":"true"},"enableLargeResultDownload":true,"maxElasticDiskCapacityGB":5000,"serverlessDefaultMinWorkers":2,"zoneInfos":[{"id":"us-west-2c","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2a","isDefault":false}],"enableCustomSpotPricingUIByTier":false,"serverlessClustersEnabled":false,"enableWorkspaceBrowserSorting":true,"enableSentryLogging":true,"enableFindAndReplace":true,"disallowUrlImportExceptFromDocs":false,"defaultStandardClusterModel":{"cluster_name":"","node_type_id":"dev-tier-node","spark_version":"3.5.x-scala2.11","num_workers":0,"aws_attributes":{"first_on_demand":0,"availability":"ON_DEMAND","zone_id":"us-west-2c","spot_bid_price_percent":100},"autotermination_minutes":120,"default_tags":{"Vendor":"Databricks","Creator":"praneethbellamkonda@gmail.com","ClusterName":null,"ClusterId":"<Generated after creation>"}},"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":true,"enableBitbucketCloud":true,"shouldShowCommandStatus":true,"createTableInNotebookS3Link":{"url":"https://docs.databricks.com/_static/notebooks/data-import/s3.html","displayName":"S3","workspaceFileName":"S3 Example"},"sanitizeHtmlResult":true,"enableJobAclsConfig":false,"enableFullTextSearch":false,"enableElasticSparkUI":false,"enableNewClustersCreate":true,"clusters":true,"allowRunOnPendingClusters":true,"useAutoscalingByDefault":false,"enableAzureToolbar":false,"fileStoreBase":"FileStore","enableEmailInAzure":false,"enableRLibraries":true,"enableTableAclsConfig":false,"enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":true,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":false,"checkBeforeAddingAadUser":false,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"createTableInNotebookDBFSLink":{"url":"https://docs.databricks.com/_static/notebooks/data-import/dbfs.html","displayName":"DBFS","workspaceFileName":"DBFS Example"},"perClusterAutoterminationEnabled":false,"enableNotebookCommandNumbers":true,"allowStyleInSanitizedHtml":true,"sparkVersions":[{"key":"1.6.3-db2-hadoop2-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-aba860a0ffce4f3471fb14aefdcb1d768ac66a53a5ad884c48745ef98aeb9d67","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.1-db6-rc-scala2.10","displayName":"Spark 2.1.1-db6 RC (Scala 2.10)","packageLabel":"spark-image-4efc0c94e152791782f2cb865ac1eb3c11985a2671a77e6ef930f9718851459d","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.0.x-rc-scala2.10","displayName":"3.0 RC (Scala 2.10)","packageLabel":"spark-image-2fdca45e0fcac7081823a5faef4f25d6fc909d11c44eca82e1dd18e9d2ef2859","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-gpu-scala2.11","displayName":"3.3 (includes Apache Spark 2.2.0, GPU, Scala 2.11)","packageLabel":"spark-image-22756288786762d246bac1381e4f44610a4c2c3135c717c5ac3661822a723f1c","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.1-db5-rc-scala2.11","displayName":"Spark 2.1.1-db5 RC (Scala 2.11)","packageLabel":"spark-image-7ce07ae16a775d917d6748d2075807565c157286f4f5957c1b77275b3b2a9bc4","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db5-scala2.11","displayName":"Spark 2.1.1-db5 (Scala 2.11)","packageLabel":"spark-image-7ce07ae16a775d917d6748d2075807565c157286f4f5957c1b77275b3b2a9bc4","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-scala2.10","displayName":"3.3 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-86a9b375074f5afad339e70230ec0ec265c4cefbd280844785fab3bcde5869f9","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1, deprecated)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.2.x-scala2.11","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-cdfb5c6299de6a2f4f5b75e8def2d11faa2026a8354185434873ec4612916663","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.1-db6-scala2.10","displayName":"Spark 2.1.1-db6 (Scala 2.10)","packageLabel":"spark-image-4efc0c94e152791782f2cb865ac1eb3c11985a2671a77e6ef930f9718851459d","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db2-scala2.11","displayName":"Spark 2.1.0-db2 (Scala 2.11)","packageLabel":"spark-image-ab147bdd6662fef83fa48e41d909aa045422585552758dc667f1971876c4486f","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-scala2.11","displayName":"4.0 (includes Apache Spark 2.3.0, Scala 2.11)","packageLabel":"spark-image-fc9368293e1b3b6c37181d7af3123a4b9de5f7fa03cfd6dfaa038753256380c9","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.5.x-rc-scala2.11","displayName":"3.5.3 RC (Scala 2.11)","packageLabel":"spark-image-36fcaa6f87fe2e83585561297f65e1ef202be7fdcce73e9d01906a41cf7ee23e","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.1.x-gpu-scala2.11","displayName":"Spark 2.1 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-d613235f93e0f29838beb2079a958c02a192ed67a502192bc67a8a5f2fb37f35","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-rc-scala2.11","displayName":"4.0.1 RC (Scala 2.11)","packageLabel":"spark-image-2bca6ba33c573262bbe6cd38beebd66ac989546ad37a50f807000654b01e37d7","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"latest-stable-gpu-scala2.11","displayName":"Latest stable (GPU, Scala 2.11)","packageLabel":"spark-image-b543c0700f83413b0055359ea9feaf285f2e2f3350fb7f301ea0e18b018b5cb5","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.4.x-scala2.11","displayName":"3.4 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-f91cb0b3822c6641a9d346ef6c149118fb859b5e511ee01c31e958892ba23c7a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db3-scala2.10","displayName":"Spark 2.0.2-db3 (Scala 2.10)","packageLabel":"spark-image-25dac86138b91b354c5882419df5c45cd3695fb36b3a14ad63ff459cd7ae28b8","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.2.x-scala2.10","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-e50cbe4c0b0ad46930872eff4b69665890fd6a170e2b1a3e48c1cdea5823fd86","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-experimental-scala2.10","displayName":"Latest experimental (Scala 2.10)","packageLabel":"spark-image-ec81b6840af02ee2321dd8dfe2587437bbcddf024d4ae287f326a98fac406a6c","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.4.x-rc-gpu-scala2.11","displayName":"3.4.3 RC (GPU, Scala 2.11)","packageLabel":"spark-image-27cc2be736ec41a80f0b5ac7839f1a08826e362c1d0e8d3c7691eb13b0c857ca","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-gpu-scala2.11","displayName":"4.0 (includes Apache Spark 2.3.0, GPU, Scala 2.11)","packageLabel":"spark-image-b543c0700f83413b0055359ea9feaf285f2e2f3350fb7f301ea0e18b018b5cb5","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.0-db1-scala2.11","displayName":"Spark 2.1.0-db1 (Scala 2.11)","packageLabel":"spark-image-e8ad5b72cf0f899dcf2b4720c1f572ab0e87a311d6113b943b4e1d4a7edb77eb","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db4-rc-scala2.10","displayName":"Spark 2.1.1-db4 RC (Scala 2.10)","packageLabel":"spark-image-0112f566715b00d5aceb1b98543285bcb3a0f38174b86abd1c096c3e861043eb","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db5-rc-scala2.10","displayName":"Spark 2.1.1-db5 RC (Scala 2.10)","packageLabel":"spark-image-07da7d24ad964d7a43f53bd9feac55de7df890ef6e5f6bac8975fb7aa3e2a0a7","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db4-scala2.11","displayName":"Spark 2.1.1-db4 (Scala 2.11)","packageLabel":"spark-image-62365f2d91529bc1128d8968f33d07f5b8d75cf7305de9455bc970e6e1fecbb4","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-scala2.11","displayName":"Latest RC (4.1 snapshot, Scala 2.11)","packageLabel":"spark-image-59b2327c8b5c512c4c409867bd04f7b6c25059da4c72c17e8927063faf6f192f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"latest-stable-scala2.11","displayName":"Latest stable (Scala 2.11)","packageLabel":"spark-image-fc9368293e1b3b6c37181d7af3123a4b9de5f7fa03cfd6dfaa038753256380c9","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.1.1-db6-rc-scala2.11","displayName":"Spark 2.1.1-db6 RC (Scala 2.11)","packageLabel":"spark-image-0067951c626cad90625cce4d2dcf3e00a1029375f8e5470d2330036d0d3c505f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.0-db2-scala2.10","displayName":"Spark 2.1.0-db2 (Scala 2.10)","packageLabel":"spark-image-0adabd34980ecfcbc6a48ac5c9e3a954cf5ec3a53a3300ae0e392c03299d89ca","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-rc-scala2.11","displayName":"3.3.3 RC (Scala 2.11)","packageLabel":"spark-image-795a80646e66c97b4226b1bc55b2453f7420f7e6dad4a6dd882bd72e8ab86ebb","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.4.x-rc-scala2.11","displayName":"3.4.3 RC (Scala 2.11)","packageLabel":"spark-image-b0a427a91495e32817455c4ee1d228450ec94203824afac61c5428d7359986ec","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db4-scala2.11","displayName":"Spark 2.0.2-db4 (Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-gpu-scala2.11","displayName":"Spark 2.0 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-968b89f1d0ec32e1ee4dacd04838cae25ef44370a441224177a37980d539d83a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"3.3.x-rc-gpu-scala2.11","displayName":"3.3.3 RC (GPU, Scala 2.11)","packageLabel":"spark-image-1afc8f6558737e43770e69f16da479d131695904dcb6cc5d72960f3e4e6b5575","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"next-major-version-scala2.11","displayName":"Next major version (4.0 snapshot, Scala 2.11)","packageLabel":"spark-image-04bb47b0bae8165f760972376ce05083bc6102645f3f3851cd1cdf9cba13d6fe","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.1.1-db4-rc-scala2.11","displayName":"Spark 2.1.1-db4 RC (Scala 2.11)","packageLabel":"spark-image-62365f2d91529bc1128d8968f33d07f5b8d75cf7305de9455bc970e6e1fecbb4","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"1.6.3-db1-hadoop2-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-fe8300ae2b3bf12c79ce76d7e9d2d03995e58d1497cfb6c0d3172efb630cb2df","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"1.6.3-db2-hadoop1-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-14112ea0645bea94333a571a150819ce85573cf5541167d905b7e6588645cf3b","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"4.0.x-rc-gpu-scala2.11","displayName":"4.0.1 RC (GPU, Scala 2.11)","packageLabel":"spark-image-f054b4c3d7515f53500f50a7b4e125df66a283f373dba9a476ae804ac476ede9","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-scala2.10","displayName":"3.5 LTS (includes Apache Spark 2.2.1, Scala 2.10)","packageLabel":"spark-image-5e4f1f2feb631875a6036dffb069ec14b436939b5efe0ecb3ff8220c835298d6","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db2-scala2.10","displayName":"Spark 2.0.2-db2 (Scala 2.10)","packageLabel":"spark-image-36d48f22cca7a907538e07df71847dd22aaf84a852c2eeea2dcefe24c681602f","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.11, deprecated)","packageLabel":"spark-image-8e1c50d626a52eac5a6c8129e09ae206ba9890f4523775f77af4ad6d99a64c44","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-rc-scala2.10","displayName":"3.3.3 RC (Scala 2.10)","packageLabel":"spark-image-fd3572a4500dd612caaf4c91e5cced98033ae969252c97eef68a19da55a154d2","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.1-db4-scala2.10","displayName":"Spark 2.1.1-db4 (Scala 2.10)","packageLabel":"spark-image-0112f566715b00d5aceb1b98543285bcb3a0f38174b86abd1c096c3e861043eb","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-scala2.10","displayName":"Latest RC (Scala 2.10)","packageLabel":"spark-image-ec81b6840af02ee2321dd8dfe2587437bbcddf024d4ae287f326a98fac406a6c","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-stable-scala2.10","displayName":"[DEPRECATED] Latest stable (Scala 2.10)","packageLabel":"spark-image-5e4f1f2feb631875a6036dffb069ec14b436939b5efe0ecb3ff8220c835298d6","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.0.2-db1-scala2.11","displayName":"Spark 2.0.2-db1 (Scala 2.11)","packageLabel":"spark-image-c2d623f03dd44097493c01aa54a941fc31978ebe6d759b36c75b716b2ff6ab9c","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.4.x-rc-scala2.10","displayName":"3.4.3 RC (Scala 2.10)","packageLabel":"spark-image-bd2c6192de1c848d8c6eb150441824e0b303c42ebc8e1a77c686cc75fa8aaa97","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db4-scala2.10","displayName":"Spark 2.0.2-db4 (Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"3.1.x-rc-scala2.10","displayName":"3.1 RC (Scala 2.10)","packageLabel":"spark-image-c6b477859faf291f56ac2dcbe6f6693d60e403c12dfcac58892b4014614363c3","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db5-scala2.10","displayName":"Spark 2.1.1-db5 (Scala 2.10)","packageLabel":"spark-image-07da7d24ad964d7a43f53bd9feac55de7df890ef6e5f6bac8975fb7aa3e2a0a7","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.4.x-gpu-scala2.11","displayName":"3.4 (includes Apache Spark 2.2.0, GPU, Scala 2.11)","packageLabel":"spark-image-66d1366768039140a9f5409f3bab414cb7477ebd8d4bbf8b32cb885120f9f705","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1, deprecated)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"latest-experimental-gpu-scala2.11","displayName":"Latest experimental (4.1 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-f03e91b93abc246deea6371995eaf8e6d78401e645acbe4cd633cf680a95be5e","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.2.x-rc-scala2.11","displayName":"3.2 RC (Scala 2.11)","packageLabel":"spark-image-3b22b5c8d5577281bcca8dd6ef07553fb32b3b99ab977f8bdb7238f850ece887","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.2.x-scala2.10","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-2fdca45e0fcac7081823a5faef4f25d6fc909d11c44eca82e1dd18e9d2ef2859","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.0.x-scala2.11","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-cdfb5c6299de6a2f4f5b75e8def2d11faa2026a8354185434873ec4612916663","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.x-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.x-scala2.10","displayName":"Spark 2.1 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-177f3f02a6a3432d30068332dc857b9161345bdd2ee8a2d2de05bb05cb4b0f4c","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.1.x-scala2.11","displayName":"3.1 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-0d3a99d46a4c55642850b5eba9aad3b56ffb9adbe8c8893403eba834399960fc","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db3-scala2.10","displayName":"Spark 2.1.0-db3 (Scala 2.10)","packageLabel":"spark-image-1f615934d3e248da8dcfb3e03bd8d92e933a17845fedb7cce12af2a0220ba6a2","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db2-scala2.11","displayName":"Spark 2.0.2-db2 (Scala 2.11)","packageLabel":"spark-image-4fa852ba378e97815083b96c9cada7b962a513ec23554a5fc849f7f1dd8c065a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.0.x-rc-scala2.11","displayName":"3.0 RC (Scala 2.11)","packageLabel":"spark-image-cdfb5c6299de6a2f4f5b75e8def2d11faa2026a8354185434873ec4612916663","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-rc-gpu-scala2.11","displayName":"3.5.3 RC (GPU, Scala 2.11)","packageLabel":"spark-image-6afab64572ea10b4b133e425aadc4817a1af48c3982cb64c300c3b795783396b","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.1.x-scala2.10","displayName":"3.1 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-c6b477859faf291f56ac2dcbe6f6693d60e403c12dfcac58892b4014614363c3","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.3.x-scala2.11","displayName":"3.3 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-46cc39a9afa43fbd7bfa9f4f5ed8d23f658cd0b0d74208627243222ae0d22f8d","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"next-major-version-gpu-scala2.11","displayName":"Next major version (4.0 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-41e21a0db3b77bc857f10358917ccbf5fbd85290e8429c2176a5fc7a29ce4f18","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-gpu-scala2.11","displayName":"3.5 LTS (includes Apache Spark 2.2.1, GPU, Scala 2.11)","packageLabel":"spark-image-7a1e78fbfc4d1645e7478daa28377389b900aec38764df46bd836c1a9925499b","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1, deprecated)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db3-scala2.11","displayName":"Spark 2.0.2-db3 (Scala 2.11)","packageLabel":"spark-image-c8547fab0cc66b918f9a64c7e35532de209d0d0e06da6078ad787ec718b37e7b","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db6-scala2.11","displayName":"Spark 2.1.1-db6 (Scala 2.11)","packageLabel":"spark-image-0067951c626cad90625cce4d2dcf3e00a1029375f8e5470d2330036d0d3c505f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.3-db1-hadoop1-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-b512ba976616af10269438701339a9bd5a97cc386737c6ecffdda5fb31c3cf20","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db1-scala2.10","displayName":"Spark 2.0.2-db1 (Scala 2.10)","packageLabel":"spark-image-654bdd6e9bad70079491987d853b4b7abf3b736fff099701501acaabe0e75c41","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.10, deprecated)","packageLabel":"spark-image-a659f3909d51b38d297b20532fc807ecf708cfb7440ce9b090c406ab0c1e4b7e","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-scala2.11","displayName":"3.5 LTS (includes Apache Spark 2.2.1, Scala 2.11)","packageLabel":"spark-image-c919ecd682175957255cbc87041d82633406312f7b74e018e165c4fe94943b5f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.1.x-rc-scala2.11","displayName":"3.1 RC (Scala 2.11)","packageLabel":"spark-image-0d3a99d46a4c55642850b5eba9aad3b56ffb9adbe8c8893403eba834399960fc","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"latest-experimental-scala2.11","displayName":"Latest experimental (4.1 snapshot, Scala 2.11)","packageLabel":"spark-image-59b2327c8b5c512c4c409867bd04f7b6c25059da4c72c17e8927063faf6f192f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.2.x-scala2.11","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-3b22b5c8d5577281bcca8dd6ef07553fb32b3b99ab977f8bdb7238f850ece887","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.x-scala2.11","displayName":"Spark 2.1 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-fdad9ef557700d7a8b6bde86feccbcc3c71d1acdc838b0fd299bd19956b1076e","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db1-scala2.10","displayName":"Spark 2.1.0-db1 (Scala 2.10)","packageLabel":"spark-image-f0ab82a5deb7908e0d159e9af066ba05fb56e1edb35bdad41b7ad2fd62a9b546","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.0.x-scala2.10","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-2fdca45e0fcac7081823a5faef4f25d6fc909d11c44eca82e1dd18e9d2ef2859","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.0-db3-scala2.11","displayName":"Spark 2.1.0-db3 (Scala 2.11)","packageLabel":"spark-image-0ea14d4a8a71de38872dd398b1139d55302680cfe3e9da217576c8304cd19b24","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-gpu-scala2.11","displayName":"Latest RC (4.1 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-f03e91b93abc246deea6371995eaf8e6d78401e645acbe4cd633cf680a95be5e","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-rc-scala2.10","displayName":"3.5.3 RC (Scala 2.10)","packageLabel":"spark-image-0903a85d2f8f5f6596b5b626f4116687a2fb0db675bef824850fba8fe14bc147","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.4.x-scala2.10","displayName":"3.4 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-867d7300605c0c54b2b1394d1bba7b88b28ed5841b3575253cded34db6ce6454","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.2.x-rc-scala2.10","displayName":"3.2 RC (Scala 2.10)","packageLabel":"spark-image-e50cbe4c0b0ad46930872eff4b69665890fd6a170e2b1a3e48c1cdea5823fd86","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]}],"enablePresentationMode":false,"enableClearStateAndRunAll":true,"enableTableAclsByTier":false,"enableRestrictedClusterCreation":true,"enableFeedback":true,"enableClusterAutoScaling":false,"enableUserVisibleDefaultTags":true,"defaultNumWorkers":0,"serverContinuationTimeoutMillis":10000,"jobsUnreachableThresholdMillis":60000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"createTableInNotebookImportedFileLink":{"url":"https://docs.databricks.com/_static/notebooks/data-import/imported-file.html","displayName":"Imported File","workspaceFileName":"Imported File Example"},"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","tableAclsDisabledMap":{"spark.databricks.acl.dfAclsEnabled":"false"},"driverStdoutFilePrefix":"stdout","showDbuPricing":true,"databricksDocsBaseHostname":"docs.databricks.com","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"i3.4xlarge":4,"class-node":1,"m4.2xlarge":1.5,"Standard_D11_v2":0.5,"r4.xlarge":1,"m4.4xlarge":3,"Standard_DS5_v2":3,"Standard_D2s_v3":0.5,"Standard_DS4_v2_Promo":1.5,"Standard_DS14":4,"Standard_DS11_v2_Promo":0.5,"r4.16xlarge":16,"Standard_DS11":0.5,"Standard_D2_v3":0.5,"Standard_DS14_v2_Promo":4,"Standard_D64s_v3":12,"p2.8xlarge":16,"m4.10xlarge":8,"Standard_D8s_v3":1.5,"Standard_E32s_v3":8,"Standard_DS3":0.75,"Standard_DS2_v2":0.5,"r3.8xlarge":8,"r4.4xlarge":4,"dev-tier-node":1,"Standard_L8s":2,"Standard_D13_v2":2,"Standard_DS13_v2_Promo":2,"Standard_E4s_v3":1,"Standard_D3_v2":0.75,"Standard_DS15_v2":5,"Standard_D16s_v3":3,"Standard_D5_v2":3,"Standard_E8s_v3":2,"Standard_DS2_v2_Promo":0.5,"c3.8xlarge":4,"Standard_D4_v3":0.75,"Standard_E2s_v3":0.5,"Standard_D32_v3":6,"Standard_DS3_v2":0.75,"r3.4xlarge":4,"Standard_DS4":1.5,"i2.4xlarge":6,"Standard_DS3_v2_Promo":0.75,"m4.xlarge":0.75,"r4.8xlarge":8,"Standard_D14_v2":4,"Standard_H16":4,"Standard_DS14_v2":4,"r4.large":0.5,"Standard_D15_v2":5,"Standard_DS12":1,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":6,"Standard_D12_v2":1,"i3.large":0.75,"memory-optimized":1,"m4.large":0.4,"Standard_D16_v3":3,"Standard_F4s":0.5,"p2.16xlarge":24,"i3.8xlarge":8,"Standard_D32s_v3":6,"i3.16xlarge":16,"Standard_DS12_v2":1,"Standard_L32s":8,"Standard_D4s_v3":0.75,"Standard_DS13":2,"Standard_DS11_v2":0.5,"Standard_DS12_v2_Promo":1,"Standard_DS13_v2":2,"c3.2xlarge":1,"Standard_L4s":1,"Standard_F16s":2,"c4.2xlarge":1,"Standard_L16s":4,"i2.xlarge":1.5,"Standard_DS2":0.5,"compute-optimized":1,"c4.4xlarge":2,"Standard_DS5_v2_Promo":3,"Standard_D64_v3":12,"Standard_D2_v2":0.5,"Standard_D8_v3":1.5,"i3.2xlarge":2,"Standard_E16s_v3":4,"Standard_F8s":1,"c3.4xlarge":2,"g2.2xlarge":1.5,"p2.xlarge":2,"m4.16xlarge":12,"Standard_DS4_v2":1.5,"c4.8xlarge":4,"i3.xlarge":1,"r3.xlarge":1,"r4.2xlarge":2,"i2.8xlarge":12},"tableFilesBaseFolder":"/tables","enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableClusterAppsUIOnServerless":false,"enableEBSVolumesUI":false,"homePageWelcomeMessage":"Welcome to ","metastoreServiceRowLimit":1000000,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":true,"enableClusterTagsUI":false,"enableNotebookHistoryDiffing":true,"branch":"2.68.34","accountsLimit":3,"enableSparkEnvironmentVariables":true,"enableX509Authentication":false,"useAADLogin":false,"enableStructuredStreamingNbOptimizations":true,"enableNotebookGitBranching":true,"local":false,"enableNotebookLazyRenderWrapper":false,"enableClusterAutoScalingForJobs":true,"enableStrongPassword":false,"showReleaseNote":true,"displayDefaultContainerMemoryGB":6,"broadenedEditPermission":false,"disableS3TableImport":false,"enableArrayParamsEdit":true,"deploymentMode":"production","useSpotForWorkers":true,"removePasswordInAccountSettings":false,"preferStartTerminatedCluster":false,"enableUserInviteWorkflow":true,"createTableConnectorOptionLinks":[{"url":"https://docs.databricks.com/_static/notebooks/redshift.html","displayName":"Amazon Redshift","workspaceFileName":"Amazon Redshift Example"},{"url":"https://docs.databricks.com/_static/notebooks/structured-streaming-kinesis.html","displayName":"Amazon Kinesis","workspaceFileName":"Amazon Kinesis Example"},{"url":"https://docs.databricks.com/_static/notebooks/data-import/jdbc.html","displayName":"JDBC","workspaceFileName":"JDBC Example"},{"url":"https://docs.databricks.com/_static/notebooks/cassandra.html","displayName":"Cassandra","workspaceFileName":"Cassandra Example"},{"url":"https://docs.databricks.com/_static/notebooks/structured-streaming-etl-kafka.html","displayName":"Kafka","workspaceFileName":"Kafka Example"},{"url":"https://docs.databricks.com/_static/notebooks/redis.html","displayName":"Redis","workspaceFileName":"Redis Example"},{"url":"https://docs.databricks.com/_static/notebooks/elasticsearch.html","displayName":"Elasticsearch","workspaceFileName":"Elasticsearch Example"}],"enableStaticNotebooks":true,"enableNewLineChart":true,"sandboxForUrlSandboxFrame":"allow-scripts allow-popups allow-popups-to-escape-sandbox allow-forms","enableCssTransitions":true,"serverlessEnableElasticDisk":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterEdit":true,"enableClusterAclsConfig":false,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableSshKeyUIByTier":false,"enableCreateClusterOnAttach":true,"defaultAutomatedPricePerDBU":0.2,"enableNotebookGitVersioning":true,"defaultMinWorkers":2,"commandStatusDebounceMaxWait":1000,"files":"files/","feedbackEmail":"feedback@databricks.com","enableDriverLogsUI":true,"enableExperimentalCharts":false,"defaultMaxWorkers":8,"enableWorkspaceAclsConfig":false,"serverlessRunPythonAsLowPrivilegeUser":false,"dropzoneMaxFileSize":2047,"enableNewClustersList":true,"enableNewDashboardViews":true,"enableJobListPermissionFilter":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"enableSparkEnvironmentVariablesUI":false,"defaultSparkVersion":{"key":"3.5.x-scala2.11","displayName":"3.5 LTS (includes Apache Spark 2.2.1, Scala 2.11)","packageLabel":"spark-image-c919ecd682175957255cbc87041d82633406312f7b74e018e165c4fe94943b5f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},"enableNewLineChartParams":false,"deprecatedEnableStructuredDataAcls":false,"enableCustomSpotPricing":false,"enableRStudioFreeUI":false,"enableMountAclsConfig":false,"defaultAutoterminationMin":120,"useDevTierHomePage":true,"disableExportNotebook":false,"enableClusterClone":true,"enableNotebookLineNumbers":true,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","commandStatusDebounceInterval":100,"showSqlEndpoints":false,"enableNotebookDatasetInfoView":true,"defaultTagKeys":{"CLUSTER_NAME":"ClusterName","VENDOR":"Vendor","CLUSTER_TYPE":"ResourceClass","CREATOR":"Creator","CLUSTER_ID":"ClusterId"},"enableClusterAclsByTier":false,"databricksDocsBaseUrl":"https://docs.databricks.com/","azurePortalLink":"https://portal.azure.com","cloud":"AWS","customSparkVersionPrefix":"custom:","disallowAddingAdmins":true,"enableSparkConfUI":true,"enableClusterEventsUI":true,"featureTier":"DEVELOPER_BASIC_TIER","mavenCentralSearchEndpoint":"http://search.maven.org/solrsearch/select","defaultServerlessClusterModel":{"cluster_name":"","node_type_id":"i3.2xlarge","spark_version":"latest-stable-scala2.11","num_workers":null,"enable_jdbc_auto_start":true,"custom_tags":{"ResourceClass":"Serverless"},"autoscale":{"min_workers":2,"max_workers":20},"spark_conf":{"spark.databricks.cluster.profile":"serverless","spark.databricks.repl.allowedLanguages":"sql,python,r","spark.databricks.acl.enabled":"false","spark.databricks.acl.sqlOnly":"false"},"aws_attributes":{"ebs_volume_count":null,"availability":"ON_DEMAND","first_on_demand":1,"ebs_volume_type":null,"spot_bid_price_percent":100,"zone_id":"us-west-2c","ebs_volume_size":null},"autotermination_minutes":0,"enable_elastic_disk":false,"default_tags":{"Vendor":"Databricks","Creator":"praneethbellamkonda@gmail.com","ClusterName":null,"ClusterId":"<Generated after creation>"}},"enableOrgSwitcherUI":true,"bitbucketCloudBaseApiV2Url":"https://api.bitbucket.org/2.0","clustersLimit":1,"enableJdbcImport":true,"enableClusterAppsUIOnNormalClusters":false,"enableElasticDisk":false,"logfiles":"logfiles/","enableRelativeNotebookLinks":true,"enableMultiSelect":true,"homePageLogo":"login/databricks_logoTM_rgb_TM.svg","enableWebappSharding":true,"enableNotebookParamsEdit":true,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"separateTableForJobClusters":true,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"enableRServerless":true,"dbcFeedbackURL":"mailto:feedback@databricks.com","enableMountAclService":true,"showVersion":true,"serverlessClustersByDefault":false,"enableWorkspaceAcls":false,"maxClusterTagKeyLength":127,"gitHash":"","clusterTagReservedPrefixes":[],"tableAclsEnabledMap":{"spark.databricks.acl.dfAclsEnabled":"true"},"showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","databricksDocsNotebookPathPrefix":"^https://docs\\.databricks\\.com/_static/notebooks/.+$","serverlessAttachEbsVolumesByDefault":false,"enableTokensConfig":false,"allowFeedbackForumAccess":true,"enablePythonVersionUI":true,"enableImportFromUrl":true,"allowDisplayHtmlByUrl":true,"enableTokens":false,"enableMiniClusters":true,"enableNewJobList":true,"enableDebugUI":false,"enableStreamingMetricsDashboard":true,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"enableJobsRetryOnTimeout":true,"loginLogo":"/login/databricks_logoTM_rgb_TM.svg","useStandardTierUpgradeTooltips":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/","enableSpotClusterType":true,"enableSparkPackages":true,"checkAadUserInWorkspaceTenant":false,"dynamicSparkVersions":true,"useIframeForHtmlResult":false,"enableClusterTagsUIByTier":false,"enableUserPromptForPendingRpc":true,"enableNotebookHistoryUI":true,"addWhitespaceAfterLastNotebookCell":true,"enableClusterLoggingUI":true,"enableDatabaseDropdownInTableUI":true,"showDebugCounters":false,"enableInstanceProfilesUI":false,"enableFolderHtmlExport":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.databricks.com/_static/notebooks/gentle-introduction-to-apache-spark.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/databricks-for-data-scientists.html","displayName":"Databricks for Data Scientists","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html","displayName":"Introduction to Structured Streaming","icon":"img/home/Python_icon.svg"}],"enableClusterStart":false,"maxImportFileVersion":5,"enableEBSVolumesUIByTier":false,"enableTableAclService":true,"removeSubCommandCodeWhenExport":true,"upgradeURL":"https://accounts.cloud.databricks.com/registration.html#login","maxAutoterminationMinutes":10000,"showResultsFromExternalSearchEngine":true,"autoterminateClustersByDefault":true,"notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":false,"showForgotPasswordLink":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"minAutoterminationMinutes":10,"accounts":true,"useOnDemandClustersByDefault":true,"enableNewProgressReportUI":true,"enableAutoCreateUserUI":true,"defaultCoresPerContainer":4,"showTerminationReason":true,"enableNewClustersGet":true,"showPricePerDBU":false,"showSqlProxyUI":true,"enableNotebookErrorHighlighting":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":1996067380363666,"name":"Spark-Live-2018","language":"scala","commands":[{"version":"CommandV1","origId":1996067380363667,"guid":"4b54c943-9338-479b-9d88-f5f73bf1459b","subtype":"command","commandType":"auto","position":2.0,"command":"%md ##Spark Live with Databricks and Apache Spark 2.3","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736085843,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ef3d0b55-06ca-4ec6-b2f4-f43dfc371890"},{"version":"CommandV1","origId":1996067380363668,"guid":"68f7f217-fd1b-41f2-8a14-ee35ab737798","subtype":"command","commandType":"auto","position":3.0,"command":"%md #### Class Logistics and Operations\n* Start, End\n* Questions\n* Lunch\n* Breaks","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736086058,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"cd19beb3-cc5b-45d3-867d-5f80535d9958"},{"version":"CommandV1","origId":1996067380363669,"guid":"99c0ebed-9a70-4444-b7f6-0c9091148902","subtype":"command","commandType":"auto","position":4.0,"command":"%md #### Topics\n\n  * Background / Architecture\n  * Querying Data with DataFrame, Dataset, SQL\n  * Brief Intro to ...\n    * Structured Streaming\n    * SparkML Machine Learning\n  * Wrap-up and open-source feature previews","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736086187,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"51f19f44-7a31-498d-a20d-6d32bfce89d6"},{"version":"CommandV1","origId":1996067380363670,"guid":"43ee3158-7fe0-4adb-ab03-433d180e50ee","subtype":"command","commandType":"auto","position":5.0,"command":"%fs ls /databricks-datasets/amazon/","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736086362,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d69faab7-3427-4991-9ab8-d1891f9723f5"},{"version":"CommandV1","origId":1996067380363671,"guid":"d3a4021c-ed3f-4ab8-9a30-28392a2668ef","subtype":"command","commandType":"auto","position":6.0,"command":"%sql SELECT * FROM parquet.`/databricks-datasets/amazon/data20K` ","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736086581,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6bb2dc0e-776a-4a8e-a901-1776219c3b33"},{"version":"CommandV1","origId":1996067380363672,"guid":"ef677026-ed85-4711-bd45-d38cfc5430aa","subtype":"command","commandType":"auto","position":7.0,"command":"%sql SELECT count(1), rating FROM parquet.`/databricks-datasets/amazon/data20K` GROUP BY rating","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736086730,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"faa00fa4-d32a-4c7b-b4ae-45ecefe3c94c"},{"version":"CommandV1","origId":1996067380363673,"guid":"bd6a5da1-54dd-42a7-99c1-a17d80e5d219","subtype":"command","commandType":"auto","position":8.0,"command":"%sql SELECT * FROM parquet.`/databricks-datasets/amazon/data20K` WHERE rating = 1 AND review LIKE '%awesome%'","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736086913,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"971f9668-c167-470d-add4-93219ff4c6f7"},{"version":"CommandV1","origId":1996067380363674,"guid":"24895190-3422-4a15-8c97-69e47c360118","subtype":"command","commandType":"auto","position":9.0,"command":"%md ####Introduction\n* What is Spark?\n  * Spark is a *distributed*, *data-parallel* compute engine ... with lots of other goodies around to make the work easier for common tasks\n* How is Spark different from ... \n  * Hadoop?\n  * RDBMSs?","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736087059,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"9aa1daca-7a3d-4de2-9824-aa8082f6d2e1"},{"version":"CommandV1","origId":1996067380363675,"guid":"732fe9c2-81c7-4db0-9854-1f3f2952c89c","subtype":"command","commandType":"auto","position":10.0,"command":"%md ####Basic Architecture\n* Spark cluster / Spark application\n  * Driver\n  * Executors\n  \n<img src=\"http://i.imgur.com/h621Rva.png\" width=\"700px\"></img>","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736087183,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d084ae35-6dd9-44c1-ad20-9026aa541f0e"},{"version":"CommandV1","origId":1996067380363676,"guid":"badb56bb-6b0c-4841-9a79-46d24371d060","subtype":"command","commandType":"auto","position":11.0,"command":"%md #### Spark application(s) vs. Underlying cluster\n\n* Spark *applications*, with their drivers and executors, are sometimes referred to as \"Spark Clusters\"\n  * __But__ that \"Spark Cluster\" is not normally a long-running thing\n  * One does not normally \"deploy machines (or VMs, or Containers) for a Spark cluster\" in the absence of a specific Spark application\n  \n* The underlying cluster -- most commonly YARN -- may have long-running nodes (hardware, VMs, etc.)\n  * *Multiple* Apache Spark application (\"Spark clusters\") can be launched in that cluster\n  * This pattern allows multiple users, teams, departments, etc. to run independent Spark applications on a common, shared infrastructure\n\n\n<img src=\"http://i.imgur.com/vJ55hxW.png\" width=\"800px\"></img>","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736087316,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5ac015d8-1175-487f-8524-eebc891f6150"},{"version":"CommandV1","origId":1996067380363677,"guid":"5bb81aa6-a2f9-4d72-ad84-24574c879916","subtype":"command","commandType":"auto","position":12.0,"command":"%md ####Programming Spark\n* Several ways\n  * Interactive (shell, notebooks)\n  * Scripts\n  * Compiled Programs\n* Languages\n  * SQL\n  * Scala\n  * Python\n  * R\n  * Java\n  * C#, F# (via Mobius)\n  * JavaScript (via Eclair)\n  * others\n  \nPrincipally: Scala, SQL, Python, R","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736087462,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"bd9d5b0c-e868-4a5b-b2ab-ab99bc11d834"},{"version":"CommandV1","origId":1996067380363678,"guid":"8f1f963c-8cdb-4c5b-9591-7378aaa5b576","subtype":"command","commandType":"auto","position":14.0,"command":"%md ####Let's Get Some Data!\n\nThe Wikimedia Project hosts a ton of analytics data -- in addition to their regular content. \n\nLet's take a look at what pages were most popular on a recent day...","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736087609,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"41bfabe0-eba5-46cf-8d74-8f97bde1e557"},{"version":"CommandV1","origId":1996067380363679,"guid":"9470d307-2016-4064-afd5-47357c53d800","subtype":"command","commandType":"auto","position":14.75,"command":"val ACCESS_KEY_ID = \"AKIAJBRYNXGHORDHZB4A\"\nval SECRET_ACCESS_KEY = \"a0BzE1bSegfydr3%2FGE3LSPM6uIV5A4hOUfpH8aFF\" \nval BUCKET = \"spark-live\"\nval MOUNT = \"/mnt/spark-live\"\n\ntry {\n  dbutils.fs.mount(\"s3a://\"+ ACCESS_KEY_ID + \":\" + SECRET_ACCESS_KEY + \"@\" + BUCKET, MOUNT)\n} catch {\n  // may be already mounted...\n  case t:Throwable => println(t)\n}","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736087741,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"28c09086-94a6-4834-9072-a32d258a61bf"},{"version":"CommandV1","origId":1996067380363680,"guid":"2c5b8a9c-df61-483e-9e70-2cc08a5c5478","subtype":"command","commandType":"auto","position":15.875,"command":"%sh ls /dbfs/mnt/spark-live","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736087888,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1129f1d2-cb12-4331-9b80-9ddbac706736"},{"version":"CommandV1","origId":1996067380363681,"guid":"32f8563f-d70f-49d2-b703-de09817d9224","subtype":"command","commandType":"auto","position":16.4375,"command":"%md How do we just take a look into a file?","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736088034,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2788f384-6193-4113-bff4-bfa1d90dca7b"},{"version":"CommandV1","origId":1996067380363682,"guid":"060c7cd3-c1aa-461a-89e2-0b79242397db","subtype":"command","commandType":"auto","position":16.71875,"command":"spark.read.text(\"/mnt/spark-live/pageviews.gz\").show(false)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736088169,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"29e63b90-4eac-4165-9073-377b613ff673"},{"version":"CommandV1","origId":1996067380363683,"guid":"42d95873-df2e-4dbc-acfe-6faea2693256","subtype":"command","commandType":"auto","position":16.859375,"command":"spark.read.option(\"delimiter\", \" \").csv(\"/mnt/spark-live/pageviews.gz\").show","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736088320,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"77e6d908-b04b-4be6-afc7-984be56f6b0b"},{"version":"CommandV1","origId":1996067380363684,"guid":"f41cea65-0f49-4f67-ba49-ca8363ea112e","subtype":"command","commandType":"auto","position":17.0,"command":"%md Let's fix the schema. We know (from Wikimedia) that the first three columns are:\n  * `project : string`\n  * `page : string`\n  * `requests : int`\t\n  * we can ignore the 4th column -- we won't be using it\n  \nOne way to do this is to use `selectExpr` and SQL snippets to `CAST` and rename the columns:","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736088467,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1a688428-1c44-4e03-bd2b-0df23f6deb6d"},{"version":"CommandV1","origId":1996067380363685,"guid":"551326af-4230-4427-8363-4f3d9ae70dbf","subtype":"command","commandType":"auto","position":17.5,"command":"val wikimediaData = spark.read\n                          .option(\"delimiter\", \" \")\n                          .csv(\"/mnt/spark-live/pageviews.gz\")\n                          .selectExpr(\"_c0 AS project\", \"_c1 AS page\", \"CAST(_c2 AS INT) AS requests\")","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736088585,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"906a8a09-1b20-405a-9653-97bb6cd2fe4a"},{"version":"CommandV1","origId":1996067380363686,"guid":"6ac191b5-2eee-4a81-9f0a-fcaff16f1570","subtype":"command","commandType":"auto","position":17.625,"command":"%md Let's give this table (really a view, or query) a name ... so that we can look at it with SQL:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736088753,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e3a0ccb4-51a3-4bf5-a0f9-ab4ad67eb37d"},{"version":"CommandV1","origId":1996067380363687,"guid":"e5fd237b-c886-46ef-a557-f039dc158cdf","subtype":"command","commandType":"auto","position":17.75,"command":"wikimediaData.createOrReplaceTempView(\"pageviews\")","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736088948,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6688d268-bf44-4c77-995e-ad442b6176aa"},{"version":"CommandV1","origId":1996067380363688,"guid":"42c46e4a-c4e8-4785-8ee9-306571cc7acc","subtype":"command","commandType":"auto","position":18.0,"command":"%sql SHOW TABLES;","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736089115,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f07e522a-e3b6-400c-9480-499e03523373"},{"version":"CommandV1","origId":1996067380363689,"guid":"b86e7186-5b24-42fd-b9bf-592a3c81b09b","subtype":"command","commandType":"auto","position":19.0,"command":"%sql DESCRIBE pageviews;","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736089279,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f3fb2d28-6f33-429f-b68f-25f6e99c0801"},{"version":"CommandV1","origId":1996067380363690,"guid":"fa493404-1584-4dd7-bb26-eb44f049cf47","subtype":"command","commandType":"auto","position":20.5,"command":"%sql SELECT * FROM pageviews WHERE project = 'en' ORDER BY requests DESC;","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736089571,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3c38ce83-3840-4609-867c-d02a56da5347"},{"version":"CommandV1","origId":1996067380363691,"guid":"663001b8-13b2-4c19-88fd-1fe7f3de4493","subtype":"command","commandType":"auto","position":21.0,"command":"%sql SELECT * FROM pageviews WHERE project = 'en' AND page LIKE '%Spark%' ORDER BY requests DESC;","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736089720,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"94a7ead3-1729-4c26-b48f-d74e8b9ba29b"},{"version":"CommandV1","origId":1996067380363692,"guid":"6d1d885f-6f36-4183-b2d5-91df4507724d","subtype":"command","commandType":"auto","position":22.0,"command":"%md We can write all kinds of SQL queries:\n\n* SQL:2003 + HiveQL ... documented at https://docs.databricks.com/spark/latest/spark-sql/index.html#spark-sql-language-manual) \n\n... and we can use a programmatic API or \"domain-specific language\" as well.\n\nThe DataFrame/Dataset API allows us to write native Python, Java, Scala, or R programs using Spark.\n\nCommon tasks are fairly similar across these APIs:\n\n|SQL|DataFame API|DataFrame example (with String column names)|\n|---|---|---|\n|SELECT|select, selectExpr|myDataFrame.select(\"someColumn\")|\n|WHERE|filter, where|myDataFrame.filter(\"someColumn > 10\")|\n|GROUP BY|groupBy|myDataFrame.groupBy(\"someColumn\")|\n|ORDER BY|orderBy|myDataFrame.orderBy(\"column\")|\n|JOIN|join|myDataFrame.join(otherDataFrame, \"innerEquiJoinColumn\")|\n|UNION|union|myDataFrame.union(otherDataFrame)|\n\nThe API support -- both for SQL and DataFrame/Dataset -- is far broader than these examples. E.g., columns and expressions can be written in a strongly-typed manner, using Column objects. These can be generated from Strings or Symbols; many types of JOIN are supported; and a variety of mechanisms for creating a DataFrame from a source exist in all of these APIs.","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736089872,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"91ca1a4f-3557-4cfe-b532-df27eeb2622b"},{"version":"CommandV1","origId":1996067380363693,"guid":"e1c11fc8-b0f4-4dfd-9b27-3f12a19758b6","subtype":"command","commandType":"auto","position":23.0,"command":"// Here's the earlier query with the DataFrame/Dataset API:\n\nval query = spark.table(\"pageviews\").filter(\"project = 'en'\").filter('page like \"%Spark%\").orderBy('requests desc)\n\ndisplay(query)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736089995,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f9e56666-c1c9-411b-aa21-be1d7478491f"},{"version":"CommandV1","origId":1996067380363694,"guid":"17550a0b-6edb-4eb0-8148-ece63a110615","subtype":"command","commandType":"auto","position":24.0,"command":"// Let's take that apart:\n\nval query = spark.table(\"pageviews\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736090160,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8e7fc48f-2139-46f8-8141-e391e275dd33"},{"version":"CommandV1","origId":1996067380363695,"guid":"2ea67cd4-8af5-43a7-9b32-64d621547127","subtype":"command","commandType":"auto","position":25.0,"command":"display(query)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736090307,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"029e3ae0-0a75-44ba-ace6-35365415451a"},{"version":"CommandV1","origId":1996067380363696,"guid":"76cab69e-fc09-45d6-958f-c3fcd5183e26","subtype":"command","commandType":"auto","position":26.0,"command":"val step1 = spark.table(\"pageviews\")\n\nval step2 = step1.filter(\"project = 'en'\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736090457,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"084886b6-a448-4292-bc64-216a48385516"},{"version":"CommandV1","origId":1996067380363697,"guid":"2b669aa9-49e4-4717-a18f-595af18250f8","subtype":"command","commandType":"auto","position":28.0,"command":"val step1 = spark.table(\"pageviews\")\n\nval step2 = step1.filter(\"project = 'en'\")\n\nval step3 = step2.filter('page like \"%Spark%\") // what is 'page here? A Scala symbol that is converted to a column object in context","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736090609,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5dec899e-ce4f-4e75-90b3-ba08fb505763"},{"version":"CommandV1","origId":1996067380363698,"guid":"5b164859-36cb-4fe7-a88b-6cf6c6875b5b","subtype":"command","commandType":"auto","position":29.0,"command":"display(step3)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736090792,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f9b73b35-6b73-4178-a515-9e94bc732344"},{"version":"CommandV1","origId":1996067380363699,"guid":"d88487ce-cdaf-4652-a28c-bf96e7053b35","subtype":"command","commandType":"auto","position":30.0,"command":"//Show me this \"page\" column object\n\nval theDataFrame = spark.table(\"pageviews\")\n\nval theColumn = theDataFrame(\"page\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736090954,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f0b4cb3a-92dc-45db-ac64-bc106c8e4207"},{"version":"CommandV1","origId":1996067380363700,"guid":"18cf7f5c-fd95-463b-bc09-d10b39d29fa8","subtype":"command","commandType":"auto","position":31.0,"command":"// So what is 'page like \"%Spark%\"? An API call on Column, that returns another Column:\n\ntheColumn.like(\"%Spark%\") // Java-style syntax, same call","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736091135,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a7c7719d-ab73-4ff9-852e-7faa91349915"},{"version":"CommandV1","origId":1996067380363701,"guid":"e5c79a13-5d27-412f-ab80-4e714a922d93","subtype":"command","commandType":"auto","position":32.0,"command":"%md ####Where do these API docs live?\n\n1. Dataset class (DataFrame is a limited but very useful form of Dataset ... it is a Dataset[Row])\n2. Column\n3. RelationalGroupedDataset and KeyValueGroupedDataset\n4. *tons* of helpful functions in org.apache.spark.sql.functions (package object) http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736091284,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d79f1da1-49e7-4b19-965c-118c911a0216"},{"version":"CommandV1","origId":1996067380363702,"guid":"2d59b207-64fe-49ab-be4b-ea09063951c7","subtype":"command","commandType":"auto","position":33.0,"command":"//One more:\n\ndisplay(spark.table(\"pageviews\").groupBy(\"project\").count().orderBy('count desc))","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736091399,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0bb3ce3d-48f8-44a7-b510-2f19f435547b"},{"version":"CommandV1","origId":1996067380363703,"guid":"17766b17-836e-41b1-8f13-394d566efb72","subtype":"command","commandType":"auto","position":34.0,"command":"%md #### Hopefully that seemed reasonable ... \n\n__but__ ... it's taking too long!\n* ... turns out our Spark code is fine in terms of API ... but the execution underneath isn't quite right yet.\n\nHow is that possible? We've barely even done anything yet and something is wrong?\n* How would we even know? How can we fix it? \n\nLet's figure it out:","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736091565,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"fd915d45-35b0-4811-ae48-0fce57d9dbd7"},{"version":"CommandV1","origId":1996067380363704,"guid":"a797002d-7fbf-4c45-9698-3d2fcc70c4b6","subtype":"command","commandType":"auto","position":35.0,"command":"%md ####Spark is a parallel cluster computing tool...\n\nso we're using lots of nodes or at least threads, right?\n\nTake a look at the parallelism in that last query. In fact, we're only using 1 thread.\n\nWe'll talk about why, and about how to fix it, but first, let's get some more terminology on the table\n* Application\n* Query\n* Job\n* Stage\n* Task\n\nNow we can at least use the Spark Graphical UI to see that we did all of that work with just one thread!","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736091693,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d06e4de0-034c-468a-a38f-c4284500551c"},{"version":"CommandV1","origId":1996067380363705,"guid":"71e808db-df2f-4597-ae1e-4962dd4b4745","subtype":"command","commandType":"auto","position":38.0,"command":"%md What was the problem? \n\nRecall the data came from wikimedia as a `gzip` file, and I didn't do any \"magic\" preparing it for today: I just dropped that .gz into the S3 bucket that we pointed Spark at.\n\nUnfortunately, gzip is not a *splittable* compression format. So Spark can't read different pieces of it in parallel using different tasks.\n\nInstead we'll convert to plain old uncompressed CSV:","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736091835,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"496b4a18-1927-4e31-81d4-7db6d8c69fc3"},{"version":"CommandV1","origId":1996067380363706,"guid":"21c9d9ab-b551-4476-b531-9e093152361d","subtype":"command","commandType":"auto","position":39.0,"command":"dbutils.fs.rm(\"/FileStore/pageviews-csv\", true) // delete any data from the destination folder (in case we run this notebook multiple times)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736091966,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f3dc02d4-d0f5-47f0-8290-e8cd6e4d9bea"},{"version":"CommandV1","origId":1996067380363707,"guid":"aff26a07-72d8-45b2-b8d5-c99af4e3643d","subtype":"command","commandType":"auto","position":40.0,"command":"spark.table(\"pageviews\").write.option(\"header\", true).csv(\"/FileStore/pageviews-csv\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736092119,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4aa24b90-dfcf-4423-a1ee-c0558325e1fa"},{"version":"CommandV1","origId":1996067380363708,"guid":"e19a87ac-a13e-4c91-8687-6fa1603c7f1b","subtype":"command","commandType":"auto","position":41.0,"command":"%md That takes a while ... remember we have to process it in one thread","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736092266,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"009b9fe8-b81f-4f88-82de-18b222f4512a"},{"version":"CommandV1","origId":1996067380363709,"guid":"e3fb38b9-64ca-43d9-a55c-46ed5161007c","subtype":"command","commandType":"auto","position":41.5,"command":"spark.table(\"pageviews\").count // USING 1 TASK","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736092389,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4a023ad0-6ab8-481d-85ae-5782c6595626"},{"version":"CommandV1","origId":1996067380363710,"guid":"b402a7ca-5f77-42ba-b50b-7025deb0f346","subtype":"command","commandType":"auto","position":42.0,"command":"spark.read.csv(\"/FileStore/pageviews-csv\").count // PARALLEL?","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736092551,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c3c6c585-3a70-474f-b32f-2dd9d112dc97"},{"version":"CommandV1","origId":1996067380363711,"guid":"4cfb5d2a-9a25-4588-bdce-872786939840","subtype":"command","commandType":"auto","position":43.0,"command":"%md That's noticeably faster, and uses 8 parallel tasks. (Remember we only have ~1 real CPU core here, so we wouldn't expect a 8x speedup)\n\nNotice:\n* 2 Jobs\n* Reading is done in parallel \n  * How is the parallelism determined?\n    * With SparkSQL in 2.0 see https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/DataSourceScanExec.scala\n    * Main number comes from defaultParallelism which is usually the total number of cores available    \n* Aggregation is required","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736092704,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f7e511bd-0f1e-49df-8b42-a86516e4ff09"},{"version":"CommandV1","origId":1996067380363712,"guid":"1e3fc62c-dc36-44b1-9e5f-e17ff92a9506","subtype":"command","commandType":"auto","position":45.0,"command":"// Let's add in a filter step and see what happens ...\n\nspark.read.option(\"header\", true).csv(\"/FileStore/pageviews-csv\").filter('project===\"en\").count","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736092824,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1ae7ef89-0607-4f9e-9794-98de6e43cad6"},{"version":"CommandV1","origId":1996067380363713,"guid":"b9bcdd3b-cbc1-4df9-ab23-f98e085fd1f5","subtype":"command","commandType":"auto","position":46.0,"command":"%md Notice that adding a filter took a little longer -- since more computation was happening -- but it did not add any tasks (or stages, jobs, etc.). \n\nThis -- inlining of \"map\" operations into tasks -- is called pipelining and is a key part of the Spark architecture. Tasks read from storage (or an external system, previous shuffle, etc.), compose *all* of the narrow operations on a partition, and then write the data out to storage, shuffle, or the driver. \n\n*So intermediate results never need to be materialized!* (this is key to handling large volumes of data efficienty)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736093002,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a502ed69-a111-43f3-871f-9b4678a021e0"},{"version":"CommandV1","origId":1996067380363714,"guid":"ff170577-a8ac-4001-85f9-4721f3044239","subtype":"command","commandType":"auto","position":46.5,"command":"%md Now we've changed formats, and we're reading a file source (no table name) and using Scala ... but is the CSV version of the data the one we really want?\n\nCSV is not the most performant (or compact) format we can use.\n\nOther things being equal, parquet is a the default recommended file format. It is a columnar, compressed file format based on the Google's Dremel paper, and it generally provides great performance on Spark, Impala, Presto and other data tools. It even supports partitioning based on the contents, so that queries don't need to process the entire dataset to find the data they are looking for.\n\n<img src=\"https://i.imgur.com/ex7zY3U.png\" width=500/>\n\nLet's rewrite our data to parquet:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736093137,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3b9f6bb9-4f8d-4ea0-9871-9363811add5b"},{"version":"CommandV1","origId":1996067380363715,"guid":"720d4c09-f906-4d08-b54f-98656d26330a","subtype":"command","commandType":"auto","position":46.625,"command":"dbutils.fs.rm(\"/FileStore/pageviews\", true) // clear out the destination folder in case we run this notebook multiple times","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736093264,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8a1446b7-8a85-477b-9a6a-2f943601e05e"},{"version":"CommandV1","origId":1996067380363716,"guid":"3bcf360f-529b-44b5-909b-1b0c51486ff3","subtype":"command","commandType":"auto","position":46.75,"command":"spark.table(\"pageviews\").write.parquet(\"/FileStore/pageviews\")","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736093423,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"cb4ca07b-071e-44de-855c-caea543860f8"},{"version":"CommandV1","origId":1996067380363717,"guid":"efa055ab-af65-4e53-8d32-0662dff55f02","subtype":"command","commandType":"auto","position":46.875,"command":"%md ... and give the new dataset a table name:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736093575,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c166f5b8-af94-403b-a4a7-1edc2a9b260b"},{"version":"CommandV1","origId":1996067380363718,"guid":"a703a110-e1a6-4368-a8d0-f77c17e9d635","subtype":"command","commandType":"auto","position":47.0,"command":"spark.read.parquet(\"/FileStore/pageviews\").filter('project===\"en\").createOrReplaceTempView(\"pv\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1519656480889,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7f387cdf-6cca-412a-b534-a02b711eadec"},{"version":"CommandV1","origId":1996067380363719,"guid":"8ddc2f30-5118-4034-ae0e-8666e5cfe061","subtype":"command","commandType":"auto","position":48.0,"command":"%md Now we can try out all sort of interesting SQL queries...","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736093852,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"9bd7fe2b-7fab-4a9d-ab97-6b0b66cb5fe7"},{"version":"CommandV1","origId":1996067380363720,"guid":"901bff01-3e31-49a1-9666-23447c0be636","subtype":"command","commandType":"auto","position":51.0,"command":"%sql SELECT * FROM pv WHERE page = 'New_York'","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736093971,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f9df96dc-e2ae-46bc-ae08-c017ca76e995"},{"version":"CommandV1","origId":1996067380363721,"guid":"460baeba-0d16-422e-a32c-97962472b8e7","subtype":"command","commandType":"auto","position":52.0,"command":"%md *Advanced Topic:* How would we speed this sort of query up in a RDBMS, or with Hive? Probably with an index.\n\nSpark does not support indices, so this flavor of query -- matching a very small fraction of records -- is not where Spark's performance shines in the default configuration.\n\nWhat do you do if you need this sort of functionality? There are a number of options, depending on your problem and architecture, but remember: \n\nSpark is a whole ecosystem, and you're not limited to just code that ships in Apache or from Databricks. E.g., one thing to look at is Intel's __Optimized Analytics Package for Spark Platform__ which adds index support: https://github.com/Intel-bigdata/OAP","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736094133,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e2821d17-e296-4be6-88b6-8d72428809a5"},{"version":"CommandV1","origId":1996067380363722,"guid":"9d19cbd7-2805-4621-833d-2c5c7adb7683","subtype":"command","commandType":"auto","position":52.25,"command":"%md Aside from noticing that your app doesn't perform well, what is another way to understand how Spark plans to run your query?\n\nWe can ask Spark to *EXPLAIN* in SQL or via the API.\n\nHere is an example query -- first, showing results; and then explaining the optimizations applied by the Catalyst rule-based optimizer:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736094257,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"07010185-be08-4884-a662-be1ae0b9822f"},{"version":"CommandV1","origId":1996067380363723,"guid":"faf6c009-685a-41c5-83c2-64a1d50e3af4","subtype":"command","commandType":"auto","position":52.5,"command":"spark.read.parquet(\"/FileStore/pageviews\").filter('project===\"en\").select('page).filter('page like \"Apache%\").show","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736094387,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"95c7363b-5907-4558-aeb1-5428f8de80cc"},{"version":"CommandV1","origId":1996067380363724,"guid":"2ab8c633-0f97-4575-8a41-acc257bc6f26","subtype":"command","commandType":"auto","position":52.75,"command":"spark.read.parquet(\"/FileStore/pageviews\").filter('project===\"en\").select('page).filter('page like \"Apache%\").explain(true)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736094550,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d780a8e4-ff2b-471a-b526-7652758f997c"},{"version":"CommandV1","origId":1996067380363725,"guid":"d1f5300d-26e5-4d47-9e96-6ce80f118d2f","subtype":"command","commandType":"auto","position":52.875,"command":"%md *Advanced topic*: Dive deep into supported qualitative optimizations by looking at https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/Optimizer.scala","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736094705,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d08f60d7-58fb-4839-ad31-e6e13d94931e"},{"version":"CommandV1","origId":1996067380363726,"guid":"8fb03f62-842c-4a8d-8788-9ad9f9f01237","subtype":"command","commandType":"auto","position":52.9375,"command":"%md What about data that we *do* know about and query a lot ... use cases borrowed from the world of analytical databases? \n\n__Spark 2.2: \"Cost-based Optimizer Framework\"__ picks up where Catalyst's existing optimizations leave off. You can see which features are included in the initial release, along with links to design, discussion, and code at https://issues.apache.org/jira/browse/SPARK-16026\n\nAs an Apache open-source project, Spark's JIRAs are public, searchable, and provide great insight into the roadmap and evolution of Spark.\n\nLet's take a quick look at the cost-based optimizer (\"CBO\") in action!","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736094826,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a48ca7dc-3761-4b68-a37a-6a3a9bc0a9eb"},{"version":"CommandV1","origId":1996067380363727,"guid":"f1c23f72-b6d4-477f-a656-27aae3aa18fa","subtype":"command","commandType":"auto","position":52.96875,"command":"%md __Join reordering__\n\nIn previous versions of Spark, joins were typically ordered based on their appearance in the query, without regard for the size of the data. This sometimes lead to inefficient nave join ordering:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736094972,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ae6acdca-99c9-42a2-9845-b50a34d52ea1"},{"version":"CommandV1","origId":1996067380363728,"guid":"c8326452-e313-4790-bc8e-7bd0b64cd47b","subtype":"command","commandType":"auto","position":52.9765625,"command":"%sql DROP TABLE IF EXISTS biglist;\nDROP TABLE IF EXISTS listsquares;\nDROP TABLE IF EXISTS small;","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516732246311,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b5e73212-b92a-41a5-a424-d8e0d602b2e1"},{"version":"CommandV1","origId":1996067380363729,"guid":"fd319e9d-239a-418f-8ecb-9e6431b456f7","subtype":"command","commandType":"auto","position":52.984375,"command":"spark.range(10000000).write.saveAsTable(\"biglist\")\nspark.range(10000000).withColumn(\"square\", 'id * 'id).write.saveAsTable(\"listsquares\")\nspark.range(1000).write.saveAsTable(\"small\")","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516732437055,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6caf6415-47e8-45e7-a077-75a599819774"},{"version":"CommandV1","origId":1996067380363730,"guid":"6f2946f9-ba14-433a-8367-01bc71c7910e","subtype":"command","commandType":"auto","position":52.9921875,"command":"spark.table(\"biglist\").join(spark.table(\"listsquares\"), \"id\").join(spark.table(\"small\"), \"id\").collect","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516732438882,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"20d76052-d31f-4f85-ac22-ec9454de2093"},{"version":"CommandV1","origId":1996067380363731,"guid":"05ff129a-acdf-4269-8a95-05d653715404","subtype":"command","commandType":"auto","position":52.99609375,"command":"%md Take a look at the Spark UI ... Look at the SQL tab, then the description link for the most recent query to see the executed plan.\n\nPretty disappointing! Spark did an expensive Sort-Merge join on all 10,000,000 rows ... and only later completed the small inner join to yield 1,000 rows.\n\n---\n\n__Ok, let's try this CBO__\n\nSetup: for open-source Spark 2.2, we would need to turn on CBO + join reordering (we can skip this on Databricks, since the config is already \"on\")\n\n```\n%sql SET spark.sql.cbo.enabled \n%sql SET spark.sql.cbo.joinReorder.enabled = true\n```\n\nNext, let's compute table-level stats for our tables:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676119211,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"84f957d0-1eaa-454a-be07-d3d92fc5543a"},{"version":"CommandV1","origId":1996067380363732,"guid":"d87bee68-2a87-4e32-9bce-2047ff67a8f0","subtype":"command","commandType":"auto","position":52.999755859375,"command":"%sql ANALYZE TABLE biglist COMPUTE STATISTICS;\nANALYZE TABLE listsquares COMPUTE STATISTICS;\nANALYZE TABLE small COMPUTE STATISTICS","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516734793975,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0659b949-8612-44fa-babf-0b7138c9cdde"},{"version":"CommandV1","origId":1996067380363733,"guid":"c0f81ebd-c3d9-4419-8d9a-7dedb0846c6c","subtype":"command","commandType":"auto","position":52.9998779296875,"command":"spark.table(\"biglist\").join(spark.table(\"listsquares\"), \"id\").join(spark.table(\"small\"), \"id\").collect","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516734794456,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"44e7e0e2-1d5e-431e-a048-511bd3413b4a"},{"version":"CommandV1","origId":1996067380363734,"guid":"4e91fc2d-a072-45f8-a7ee-8e579be250de","subtype":"command","commandType":"auto","position":52.99993896484375,"command":"%md Look at the executed plan for this version ... the join is reordered to avoid the large (10,000,000 row <-> 10,000,000 row) join.\n\nNow let's look at one more feature. What if we add a filter condition so that we only keep 100 rows from the `squares` table. In that case, the \"original\" plan might be better -- join the big table to the tiny list of squares, yielding 100 rows, then join the `small` table.\n\nAs a baseline, let's observe that Spark doesn't do this optimization, because it doesn't know the distribution of data in the `square` column, so it can't yet estimate how many rows are involved:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676120288,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3b0e9f3a-80e1-4dc0-acda-58e011e625c5"},{"version":"CommandV1","origId":1996067380363735,"guid":"9af44b34-199b-407e-9948-06a38c4e9d86","subtype":"command","commandType":"auto","position":52.999969482421875,"command":"spark.table(\"biglist\").join(spark.table(\"listsquares\").filter('square < 10000), \"id\").join(spark.table(\"small\"), \"id\").collect","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516734845730,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ae41d430-a282-4017-b56b-86cd49924657"},{"version":"CommandV1","origId":1996067380363736,"guid":"f9b10505-4444-49cb-93d7-af6931b4425e","subtype":"command","commandType":"auto","position":52.99998474121094,"command":"%md Note the SQL UI shows the same query plan as before -- adding the `filter` didn't change anything for Spark.\n\nLet's have Spark build column-level statistics on that table and try again:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676120589,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3b187d9e-2e38-4d3f-a3af-5addc987b086"},{"version":"CommandV1","origId":1996067380363737,"guid":"43b532b8-963d-4367-bf63-6e854899de0e","subtype":"command","commandType":"auto","position":52.99999237060547,"command":"%sql ANALYZE TABLE listsquares COMPUTE STATISTICS FOR COLUMNS id, square","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516734894192,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"afaaef00-2123-4b04-acbb-ebfc83b8fbb3"},{"version":"CommandV1","origId":1996067380363738,"guid":"26786067-b050-44e5-9f6b-45733c46338c","subtype":"command","commandType":"auto","position":52.999996185302734,"command":"spark.table(\"biglist\").join(spark.table(\"listsquares\").filter('square < 10000), \"id\").join(spark.table(\"small\"), \"id\").collect","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516734894994,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"77141973-6b19-489f-b257-a36ccc36dfab"},{"version":"CommandV1","origId":1996067380363739,"guid":"124140b7-d14b-4c94-a554-73130a88c649","subtype":"command","commandType":"auto","position":52.99999809265137,"command":"%md Referring to the SQL UI, we can see that this change resulted in two improvements:\n\n* The __join ordering is optimal and takes into account the `filter`__ that keeps just 100 rows of the squarelist table\n* With the additional size data, __Spark avoids the Sort-Merge join and performs both joins as Broadcast__ joins \n\n*This is just a brief look at the CBO technology in Spark 2.2. For more details, look at the presentations from Spark Summit SF 2017:*\n\n* Cost Based Optimizer in Apache Spark 2.2 (Part 1) - Ron Hu & Sameer Agarwal https://www.youtube.com/watch?v=qS_aS99TjCM\n* Cost Based Optimizer in Apache Spark 2.2 (Part 2) - Zhenhua Wang & Wenchen Fan https://www.youtube.com/watch?v=8J-qffTYheE\n* Slides accompanying those sessions - https://www.slideshare.net/databricks/costbased-optimizer-in-apache-spark-22\n\n__Takeaway: Benchmarking Perf Improvements on TPC-DS__\n* 16 queries show speedup > 30%\n* Max speedup is 8x\n* Geometric mean of speedup is 2.2x","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676121063,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"32274ec6-b83d-472d-a314-b19caa7e059e"},{"version":"CommandV1","origId":1996067380363740,"guid":"1fa75e1c-e780-4579-8588-e3a23fd37c3b","subtype":"command","commandType":"auto","position":53.0,"command":"%md #### Returning to the surface from our deep dive...\n\nLet's try a practical business use case: we'll join our pageview data with some geography data and see whether big cities get searched more than small ones","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676121345,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7b735f35-dae4-4fd5-bff9-702863e82dc1"},{"version":"CommandV1","origId":1996067380363741,"guid":"e7015e6c-604f-40f8-a314-067dd3d11bca","subtype":"command","commandType":"auto","position":54.0,"command":"%fs ls /mnt/spark-live","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736095981,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3f647e9f-2b88-4acf-81e9-e36bfeb432c4"},{"version":"CommandV1","origId":1996067380363742,"guid":"362202c0-677a-4785-8ce7-5c3cc4e73db9","subtype":"command","commandType":"auto","position":57.0,"command":"spark.read.json(\"/mnt/spark-live/zips.json\").withColumnRenamed(\"_id\", \"zip\").createOrReplaceTempView(\"zip\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1521415600616,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0cd8404f-1eb2-40f2-b492-b424e3aaa286"},{"version":"CommandV1","origId":1996067380363743,"guid":"5bea9681-cce8-431f-aac8-e9e564134481","subtype":"command","commandType":"auto","position":58.0,"command":"%sql SELECT * FROM zip","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736097019,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8bf71ed2-dd9f-48bc-819d-c797df71177e"},{"version":"CommandV1","origId":1996067380363744,"guid":"b3a35e29-feba-4391-99d7-045ad3f06913","subtype":"command","commandType":"auto","position":59.0,"command":"%sql SELECT page, pop, requests FROM pv JOIN zip ON page = city ORDER BY requests DESC;","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736097263,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4230c4bb-0f0a-4231-88bc-0aabf14d9022"},{"version":"CommandV1","origId":1996067380363745,"guid":"a71f1536-4726-4574-b21b-6819e08033bb","subtype":"command","commandType":"auto","position":60.0,"command":"%md That works ... but ... business logic fail!\n* New\\_York (in Wikipedia) won't match NEW YORK in the zips dataset\n* and there are multiple postcodes for many of the named cities\n\nLet's see if there are some built-in funtions that might help:","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676122204,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5690525b-117f-4da3-8f7b-476b51979c69"},{"version":"CommandV1","origId":1996067380363746,"guid":"a9c8913d-453a-4ee0-bd6f-f0ab96233d2c","subtype":"command","commandType":"auto","position":61.0,"command":"%sql SHOW FUNCTIONS","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736098249,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"fe87a089-f17d-48da-aa12-87d2eaf3677f"},{"version":"CommandV1","origId":1996067380363747,"guid":"58e2690f-e4ac-4629-ba31-4a7ada28b69c","subtype":"command","commandType":"auto","position":62.0,"command":"%sql SELECT split(page, '_') FROM pv WHERE page LIKE 'New_%'","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736098568,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"9c8aeeee-cb69-4c88-8e26-67c280ce9574"},{"version":"CommandV1","origId":1996067380363748,"guid":"c5d3fc1c-0efa-4611-b961-60f90bdffa5f","subtype":"command","commandType":"auto","position":62.25,"command":"%md Ok, how about our report of Wikipedia requests for large cities:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676122721,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0ab2bf29-9920-4f93-a90e-cbaadf6ffda0"},{"version":"CommandV1","origId":1996067380363749,"guid":"a8d0279e-27c9-4d32-b918-c7ba103be3f4","subtype":"command","commandType":"auto","position":62.5,"command":"%sql SELECT city, SUM(pop), FIRST(requests) \n     FROM pv\n     JOIN zip ON lower(page) = regexp_replace(lower(city), ' ', '_') \n     GROUP BY city \n     ORDER BY FIRST(requests) DESC;\n     \n-- This does ignore cities that with the same name in multiple states (e.g., Portland, Maine; Portland, Oregon) but the very largest cities aren't affected","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1519660765154,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4e40578c-2912-4e0d-8d70-65f7680f7f6a"},{"version":"CommandV1","origId":1996067380363750,"guid":"1632020f-d0a5-486d-9fd0-765fe6a08734","subtype":"command","commandType":"auto","position":62.75,"command":"%md Something fishy is going on though: look at San Francisco's population ... that's way too high.\n\n__Exercise__: Can you find the real population data in the zip table, and figure out what's going wrong?","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676123025,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"139e11b4-2583-4e6a-a04b-ab7675bdfb3c"},{"version":"CommandV1","origId":1996067380363751,"guid":"956b0236-14f4-41af-8749-80819d03809d","subtype":"command","commandType":"auto","position":62.875,"command":"// try it!\n","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736099445,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"31bddc5f-18f9-4332-8721-12dff2e8399a"},{"version":"CommandV1","origId":1996067380363752,"guid":"e64e3143-f685-4e55-9b43-1473da7c9e9e","subtype":"command","commandType":"auto","position":63.0,"command":"%md Now, if we really needed to, we *could* code our own functions as well:","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676123399,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4498769c-5ae7-4a14-b5a7-12176c40a3d3"},{"version":"CommandV1","origId":1996067380363753,"guid":"818090f6-345a-429b-bde4-88a7c31ad9da","subtype":"command","commandType":"auto","position":64.0,"command":"val isOdd = spark.udf.register(\"isOdd\", (n:Long) => n%2 == 1 )","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736100164,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e875710c-0f3a-4f3b-b579-90893091ba67"},{"version":"CommandV1","origId":1996067380363754,"guid":"99921036-5d0f-49f8-9c4f-117ca1694da7","subtype":"command","commandType":"auto","position":65.0,"command":"val someNumbers = spark.range(20)\n\nsomeNumbers.select('id, isOdd('id)).show","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736100803,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"01301238-9968-4088-a394-aa62a7450a6f"},{"version":"CommandV1","origId":1996067380363755,"guid":"6b6795d0-630f-4f03-a7f8-a9d62db35849","subtype":"command","commandType":"auto","position":66.0,"command":"%sql SELECT id, isOdd(id) FROM range(10)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736101105,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0a522b34-4e36-4afe-9941-3062832515f7"},{"version":"CommandV1","origId":1996067380363756,"guid":"0cc48374-4f6a-43e2-ac93-fb67a821d9e4","subtype":"command","commandType":"auto","position":86.0,"command":"%md *Advanced Topic:* We can also look at rows -- including just parts of rows, or rows with embedded data structures! -- as a Scala type. This feature is called typed Dataset and allows you to leverage nearly all of the performance-enhancing features of Catalyst and Tungsten, while still having access to native Scala types when you need them.\n\nWhy? Sometimes we need to call our existing custom business logic (perhaps Java) or it's easier to express a query or aggregation in code:","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676124434,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3e508a45-8ac5-45b2-9571-600e684ce9c1"},{"version":"CommandV1","origId":1996067380363757,"guid":"3094c821-a360-4579-8aa7-29ffe050c22a","subtype":"command","commandType":"auto","position":87.0,"command":"case class Zip(city:String) {\n  def isSpecial = {\n    city contains \"BACON\" // complex, legacy, regulated, or otherwise special business logic!\n  }\n}\n\nspark.table(\"zip\").as[Zip].filter(_.isSpecial).show","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736101633,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ac66d363-8d41-44ee-adb0-89a124c16fd6"},{"version":"CommandV1","origId":1996067380363758,"guid":"eadcb7ce-652e-45ef-8f20-711d86a4e633","subtype":"command","commandType":"auto","position":89.0,"command":"case class Zip(city:String, state:String, zip:String)\ndisplay(\n  spark.table(\"zip\")\n    .as[Zip].groupByKey(z => z.city + \"|\" + z.state)\n    .reduceGroups( (z1, z2) => Zip(z1.city, z1.state, z1.zip + \" \" + z2.zip) )\n)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736101924,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"824ad16f-cc13-46aa-86d6-817e9f76a063"},{"version":"CommandV1","origId":1996067380363759,"guid":"754b6931-3d35-4fed-9f4d-d0f999aab893","subtype":"command","commandType":"auto","position":97.75,"command":"%md #### What about Python?\n\nThis particular approach -- \"Dataset\" -- is Scala-only, and, in the past, mixing Python code with Spark DataFrame code was a major performance anti-pattern.\n\nBut __Spark 2.3__ introduces a building block for major improvements in Spark + Python interoperability, especially exciting because it opens the door to elegant integrations between Spark and the Python scientific computing, data science, and machine learning stack, including such favorites as SciPy, NumPy, Pandas, TensorFlow, PyTorch, Numba, Scikit-Learn, and more.\n\nThis new capability takes the form of:\n* Vectorized Pandas scalar UDFs\n* Vectorized Pandas group-map UDFs (partial aggregations / flatmap groups to any number of rows)\n* Integration with Apache Arrow, a columnar in-memory format supporting zero-copy reads (https://arrow.apache.org/)\n\n<img src=\"https://i.imgur.com/DQkDbUH.png\" width=900>","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e950ec20-8ec9-49bd-92d1-10ffe69202e9"},{"version":"CommandV1","origId":1996067380363760,"guid":"40f88456-254a-4526-b95e-5986481b47f0","subtype":"command","commandType":"auto","position":102.125,"command":"%md __This sounds like a complex integration! The API must be crazy! ... Actually, it's really easy:__","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"fd62d443-b884-4073-b001-de9ddebae456"},{"version":"CommandV1","origId":1996067380363761,"guid":"12383dbb-59bb-4722-a75c-8f5fe9395f28","subtype":"command","commandType":"auto","position":104.3125,"command":"%python\n\nfrom pyspark.sql.functions import pandas_udf, PandasUDFType\n\ndf = spark.createDataFrame(\n  [(9, 100, 0, 56), (17, 0, 150, 0), (25, 50, 75, 56)], #grams\n  (\"bacon\", \"eggs\", \"sausage\", \"spam\"))\n\ndf.show()","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1521415361626,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"805a542c-a710-442e-8992-87f8743621a9"},{"version":"CommandV1","origId":1996067380363762,"guid":"6212823e-a6ee-4254-80b6-42792d5570c3","subtype":"command","commandType":"auto","position":105.40625,"command":"%python\n\n# important business method, or machine learning model!\n@pandas_udf(\"float\", PandasUDFType.SCALAR)\ndef total_calories(bacon, eggs, sausage, spam):\n  return 5.41*bacon + 1.96*eggs + 3.01*sausage + 2.8*spam\n  \n  \n# use it like any other function of column(s):\ndf.withColumn(\"calories\", total_calories(*df.columns)).show()","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1521415453367,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"eb0e5cc9-b3c9-4b76-baee-4687684d34d9"},{"version":"CommandV1","origId":1996067380363763,"guid":"3b585c10-889a-4bca-8ee5-ff2468a03a28","subtype":"command","commandType":"auto","position":105.953125,"command":"%python\n\nimport pandas as pd\n\n@pandas_udf(\"city STRING, state STRING, zip STRING\", PandasUDFType.GROUPED_MAP) \n\n# Input/output are both a pandas.DataFrame\ndef merge_zips(pdf):    \n    zips = pdf['zip'].str.cat(sep=' ')  \n    return pd.DataFrame([[pdf['city'][0], pdf['state'][0], zips]], columns=['city','state','zips'])\n\nout = spark.table(\"zip\").filter(\"city IN ('BOSTON', 'CHICAGO', 'AUSTIN')\") \\\n  .select(\"city\", \"state\", \"zip\").groupby(\"city\", \"state\") \\\n  .apply(merge_zips)\n\ndisplay(out)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1521417382796,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ec22e6a4-c2a9-4078-9d9b-744761deaa7b"},{"version":"CommandV1","origId":1996067380363764,"guid":"86067dc6-e442-4c52-b936-dd3af5cc3938","subtype":"command","commandType":"auto","position":106.2265625,"command":"%md That's a bit of a silly example, but we could also be ...\n\n* collecting characteristic statistics by group\n* normalizing or anonymizing (you can return multiple rows per group)\n* building models (there's an example in this post https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html)\n* deskewing based on their within-group distribution\n\nor anything else!\n\n*Note that Arrow is not used unless you install pyarrow and turn it on via config*\n\nTake a look at some more details and examples: https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"70e37d72-4c3b-44b8-bebd-ed8675eb2941"},{"version":"CommandV1","origId":1996067380363765,"guid":"a83e3740-d0b3-4008-b31a-2cb5b626f334","subtype":"command","commandType":"auto","position":106.5,"command":"%md ##Machine Learning with Spark + Databricks","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676125337,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"983edb5f-cf30-4758-bb26-ae4be694e0e9"},{"version":"CommandV1","origId":1996067380363766,"guid":"f13f2a50-48ab-4131-a598-b420ab06faf1","subtype":"command","commandType":"auto","position":108.0,"command":"%python\n\npath = \"/databricks-datasets/Rdatasets/data-001/csv/ggplot2/diamonds.csv\"\n\nspark.read.csv(path).show()","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736102979,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"183c4960-06be-4ae3-9796-a6aac56f24d2"},{"version":"CommandV1","origId":1996067380363767,"guid":"cb9872bc-be16-47e3-962f-4071530d7bd0","subtype":"command","commandType":"auto","position":109.0,"command":"%md We can use the header data as column names through the regular reader option call:","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676125733,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ab25eaf6-6e4b-401c-b9e6-ed53db2e5137"},{"version":"CommandV1","origId":1996067380363768,"guid":"dad9920c-e26b-4639-b619-867964c8340e","subtype":"command","commandType":"auto","position":110.0,"command":"%python\n\nspark.read.option(\"header\", True).csv(path).show()","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736103452,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ba75006f-752b-4d73-aa74-66a2bf434db3"},{"version":"CommandV1","origId":1996067380363769,"guid":"f4803b0a-9414-47da-8254-1592f2572f7f","subtype":"command","commandType":"auto","position":111.0,"command":"%md In this example, we're just going to look at carat weight as a linear predictor of price. So we'll grab those columns and use the inferSchema option to get numbers (recall the original data is a CSV file which defaults to reading strings):","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676126270,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"576523ac-ac94-4ab4-bef8-92fa521c243c"},{"version":"CommandV1","origId":1996067380363770,"guid":"f85df094-c2f2-4c27-8e97-2d2f6ed9b4ae","subtype":"command","commandType":"auto","position":112.0,"command":"%python\n\ndata = spark.read.option(\"header\", True) \\\n            .option(\"inferSchema\", True) \\\n            .csv(path) \\\n            .select(\"carat\", \"price\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736103934,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"9ad76518-b3bb-4e97-a0a3-d7ac6a36e997"},{"version":"CommandV1","origId":1996067380363771,"guid":"4b3816a2-ea97-4a75-afd3-95bbc98410ff","subtype":"command","commandType":"auto","position":113.0,"command":"%md Let's have a quick look to see if there's any hope for our linear regression:","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676126822,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2d2b54a7-220e-4646-b16b-c8dab07f8726"},{"version":"CommandV1","origId":1996067380363772,"guid":"29769328-8927-49c8-a9b8-25937eeb09fd","subtype":"command","commandType":"auto","position":114.0,"command":"%python\n\ndisplay(data.sample(False, 0.01))","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736104408,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"scatterPlot","width":"627","height":"378","xColumns":[],"yColumns":["carat","price"],"pivotColumns":[],"pivotAggregation":"sum","customPlotOptions":{"scatterPlot":[{"key":"loess","value":false},{"key":"bandwidth","value":"0.3"}]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4c21b7c4-40b5-47a6-bef6-8ba907aff349"},{"version":"CommandV1","origId":1996067380363773,"guid":"b78c80c7-c802-4ecf-9bef-2865af74fc69","subtype":"command","commandType":"auto","position":115.0,"command":"%md What's the Pearson correlation?","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676127256,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8c10d262-13f6-46b3-8faa-f841d41620c8"},{"version":"CommandV1","origId":1996067380363774,"guid":"b9fa3b2a-1e7e-4b03-a414-f60cf356ec72","subtype":"command","commandType":"auto","position":116.0,"command":"%python\n\ndata.stat.corr(\"price\", \"carat\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736104985,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4700a8ec-d2ab-40a3-8da9-822091aa5f6f"},{"version":"CommandV1","origId":1996067380363775,"guid":"f134df4e-02cd-4b71-b549-b0e2036fe872","subtype":"command","commandType":"auto","position":117.0,"command":"%md Ok, so there is a chance we'll get something useful out... \n\nBut what do we need to feed in?\n\nVectors!\n\nThe training (and validation, test, etc.) data needs to be collected into a column of Vector[Double]\n\nWe could do this conversion ourselves, by writing a UDF, but luckily, there's a built-in `Transformer` that will take one or more columns of numbers and collect them into a new column containing a Vector[Double]","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676127880,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"012976b5-f10b-4898-adb0-d7a9a6d67b57"},{"version":"CommandV1","origId":1996067380363776,"guid":"a5cb8b87-33bf-47f8-9e50-35b1379701ad","subtype":"command","commandType":"auto","position":118.0,"command":"%python\n\nfrom pyspark.ml.feature import *\n\nassembler = VectorAssembler(inputCols=[\"carat\"], outputCol=\"features\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736105458,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7975faae-53cb-47b5-bd7f-6a09223ea2e9"},{"version":"CommandV1","origId":1996067380363777,"guid":"3ad5421a-45ae-4faa-adf9-b8fefcc405ee","subtype":"command","commandType":"auto","position":119.0,"command":"%md First look at the next cell, to help make it concrete what this transformer does, and what transformers do in general.\n\nNext, take a look at the VectorAssembler docs and maybe even the source code.","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676128719,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6261b145-d138-495b-bb3f-5da1b8690807"},{"version":"CommandV1","origId":1996067380363778,"guid":"fe0debaf-c79e-4c15-a7c7-9b28d2c5ec44","subtype":"command","commandType":"auto","position":120.0,"command":"%python\n\nassembler.transform(data).show()","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736105947,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c0e7adaa-a982-499b-9b79-30ce78240291"},{"version":"CommandV1","origId":1996067380363779,"guid":"4fead6ee-0e39-4adb-8b9b-f7d2c17d18e9","subtype":"command","commandType":"auto","position":121.0,"command":"%md Now we'll add the `LinearRegression` algorithm. The algorithm builds a model from data.\n\nSince it needs to look at all the data and then build a new piece of state (representing the `Model`) that can be used for predictions on each row (a Model is a subtype of `Transformer`), it is an `Estimator`.","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676129395,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"aaacd86b-d764-4fb1-855b-3edccf497653"},{"version":"CommandV1","origId":1996067380363780,"guid":"213857fa-6e54-474f-93b6-ca76c1dcd733","subtype":"command","commandType":"auto","position":122.0,"command":"%python\n\nfrom pyspark.ml.regression import *\n\nlr = LinearRegression(labelCol=\"price\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736106516,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"bab24310-7a13-4f40-ae8f-aabcd4d036f0"},{"version":"CommandV1","origId":1996067380363781,"guid":"07e72035-9324-4407-9ccf-5f8631191e32","subtype":"command","commandType":"auto","position":123.0,"command":"%md We can operate each of these components separately, to see how they're working (but we'll see a shortcut in just a minute)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676129816,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"23b8cde9-63dd-4cb0-997e-84e33746bf4f"},{"version":"CommandV1","origId":1996067380363782,"guid":"a3d650bd-e383-452d-9248-013f2242309d","subtype":"command","commandType":"auto","position":124.0,"command":"%python\n\ntrain, test = data.randomSplit([0.75, 0.25])\n\nlrModel = lr.fit ( assembler.transform(train) )\n\nlrModel.transform( assembler.transform(test) ).show()","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736107417,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"bdfb96ce-ca1e-4cef-a4c0-8643a2cf346a"},{"version":"CommandV1","origId":1996067380363783,"guid":"fac2c5dc-c85b-4baa-a35c-63c883d3e479","subtype":"command","commandType":"auto","position":125.0,"command":"%md Let's package the processing steps together so that we don't need to run them\n* separately\n* for training, validation sets, etc.\n\nThe `Pipeline` is an `Estimator` that represents composing a series of `Transformer`s or `Estimator`-`Model` pairs.\n\nWhen we add an `Estimator` to a pipeline (without specifically fitting the `Estimator` first), we are performing composition -- `Pipeline`s are themselves `Estimator`s, so we're making a new `Estimator` that includes the `LinearRegression` algorithm as a component part.","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676130586,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f818e712-a337-4729-8ee9-85f12b06f83f"},{"version":"CommandV1","origId":1996067380363784,"guid":"f51c0e5a-beab-4b93-9f96-abb68216c316","subtype":"command","commandType":"auto","position":126.0,"command":"%python\n\nfrom pyspark.ml import Pipeline\n\npipeline = Pipeline(stages=[assembler, lr])","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736108055,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ced6fdf3-7d15-46f0-a2e0-2dd34a2264f0"},{"version":"CommandV1","origId":1996067380363785,"guid":"883f78d8-ea8b-4a6c-935a-61b174d517b3","subtype":"command","commandType":"auto","position":127.0,"command":"%python\n\nmodel = pipeline.fit(train)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736108819,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"dcd3d5ba-8c6d-4175-8fec-2db70208b7cb"},{"version":"CommandV1","origId":1996067380363786,"guid":"5c3346df-b1be-44c2-9dd6-43e0acfa9c15","subtype":"command","commandType":"auto","position":127.75,"command":"%md Note this is a summary of the model, not a summary of the test. So it's showing training error, or \"apparent error.\"","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676132712,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1bd85fbf-de1f-4531-a414-c9cd42d198b1"},{"version":"CommandV1","origId":1996067380363787,"guid":"a24c1ef1-5ff5-4ece-968a-326a2bc16feb","subtype":"command","commandType":"auto","position":127.875,"command":"%python\n\nsummary = model.stages[-1].summary\nprint(summary.r2)\nprint(summary.rootMeanSquaredError)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736109225,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e5f4717b-f7df-4195-a8db-7d3bd872b2bc"},{"version":"CommandV1","origId":1996067380363788,"guid":"7b465a6b-6a73-49f0-bd1e-262bf5f44c92","subtype":"command","commandType":"auto","position":127.9375,"command":"%python\n\ndisplay(summary.residuals.sample(False, 0.05)) # training residuals","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736109777,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"histogram","width":"593","height":"422","xColumns":[],"yColumns":["residuals"],"pivotColumns":[],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"histogram":[{"key":"bins","value":"40"}]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4460102d-e4c6-4120-b4df-4d49508edd71"},{"version":"CommandV1","origId":1996067380363789,"guid":"db6c91e6-f2f1-440b-81e4-d882b4dbdd2a","subtype":"command","commandType":"auto","position":127.96875,"command":"%md Now ... how did we do on test data?","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676134296,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"09b5b693-774b-45c7-b64d-cbf7de9471a2"},{"version":"CommandV1","origId":1996067380363790,"guid":"a1d9e08a-00d7-448e-af7e-797ba48d16cc","subtype":"command","commandType":"auto","position":128.0,"command":"%python\n\npredictions = model.transform(test)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736110748,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c5104057-de6f-43b6-92ee-b25aeff2cb56"},{"version":"CommandV1","origId":1996067380363791,"guid":"7b7a1b3c-b1e0-4b01-9cc5-d2de70114bbf","subtype":"command","commandType":"auto","position":130.0,"command":"%python\n\ndisplay(predictions.sample(False, 0.02).selectExpr(\"prediction - price as error\"))","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736111467,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"histogram","width":"659","height":"431","xColumns":[],"yColumns":["error"],"pivotColumns":[],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"histogram":[{"key":"bins","value":"40"}]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"cab2d29c-fb82-4a00-be8e-7d782010ae43"},{"version":"CommandV1","origId":1996067380363792,"guid":"3576b8ea-b414-4938-8ab2-8231c92350f1","subtype":"command","commandType":"auto","position":136.0,"command":"%python\n\nfrom pyspark.ml.evaluation import *\n\neval = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736112034,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"974294bd-f137-4129-9358-1d63863cb558"},{"version":"CommandV1","origId":1996067380363793,"guid":"fb4399f2-4197-43cd-94d7-a6f3fd429ba8","subtype":"command","commandType":"auto","position":137.0,"command":"%python\n\neval.evaluate(predictions)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736112746,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7d6d147b-e4bc-4a7e-ba28-56d8524e1525"},{"version":"CommandV1","origId":1996067380363794,"guid":"41ec2c98-c3c6-4048-b770-130a6c56f437","subtype":"command","commandType":"auto","position":138.0,"command":"%python\n\nfor line in eval.explainParams().split(\"\\n\"):\n  print(line)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736113540,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"cbdf882f-677c-45a1-9767-3a3b331d84cf"},{"version":"CommandV1","origId":1996067380363795,"guid":"6a112d25-d7c9-4b71-ab91-5622747c14e8","subtype":"command","commandType":"auto","position":138.5,"command":"%python\n\nhelp(eval)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736114378,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4406c440-330f-453c-bff0-5afca6ebbaed"},{"version":"CommandV1","origId":1996067380363796,"guid":"09ac5cea-664a-4cf3-af92-8170a84d290a","subtype":"command","commandType":"auto","position":142.0,"command":"%md It looks like we did about as well (or badly) on the test data as on the training data.","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676139730,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b191ece6-e985-4107-a9e1-c7e4e43f2e4b"},{"version":"CommandV1","origId":1996067380363797,"guid":"61c2cbfe-2df0-4fae-b3db-40aff08720f5","subtype":"command","commandType":"auto","position":146.0,"command":"%md Recap... What have we looked and not looked at?\n\nLooked at:\n* Basic data preparation (types, DataFrame, vectors)\n* Feature pre-processing helper example: VectorAssembler\n* Role and type of a Transformer\n* Model-building algorithm example: LinearRegression\n* Role and type of an Estimator\n* Pipeline\n* Some basic graphs and statistics along the way\n\nHave *not* looked at:\n* Cleaning, deskewing, other data pre-processing\n* Various data prep helpers\n* Other algorithms\n* Model tuning and cross-validation\n* Combining Spark with other models and tools (sklearn, deep learning, etc.)\n* Data-parallelism strategy","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676142301,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"28f13736-4e4f-4cdc-a416-90777aa441cf"},{"version":"CommandV1","origId":1996067380363798,"guid":"416b8472-a03e-490b-9da9-184408ceea4e","subtype":"command","commandType":"auto","position":146.5,"command":"%md One-variable linear regression? Really? Can't we do something a tiny bit fancier?\n\nFor the data scientists, we'll take a quick look at a more powerful model -- a gradient-boosted tree ensemble -- using all of the features in the dataset:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676142424,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"43f168e5-6a0f-49e0-be4c-3ef83d8f386a"},{"version":"CommandV1","origId":1996067380363799,"guid":"f0cc64c8-4a81-492a-9af2-ef743274dfdd","subtype":"command","commandType":"auto","position":146.75,"command":"%python\n\ncategoricalFields = [\"cut\", \"color\", \"clarity\"]\n\nindexers = [StringIndexer(inputCol=f, outputCol=f + \"Index\") for f in categoricalFields]\n\nassembler = VectorAssembler( \\\n  inputCols=[f + \"Index\" for f in categoricalFields] + [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"], \\\n  outputCol=\"features\")\n\ngbt = GBTRegressor(labelCol=\"price\")\ngbtPipeline = Pipeline(stages=indexers + [assembler, gbt])\n\nallFields = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(path)\ntrain, test = allFields.randomSplit([0.75, 0.25])\n\ngbtModel = gbtPipeline.fit(train)\npredictions = gbtModel.transform(test)\neval.evaluate(predictions)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516736117074,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b3d54469-9e14-4d1d-b96d-c4de77f48e23"},{"version":"CommandV1","origId":1996067380363800,"guid":"62961739-c546-496b-bb2f-0701ecf51aa8","subtype":"command","commandType":"auto","position":146.875,"command":"%md ####What about Deep Learning?\n\n__Training Full Models in Spark__\n  * Intel BigDL - CPU focus\n  * DeepLearning4J - GPU support\n  * dist-keras - Keras API + distributed research-grade algorithms + GPU\n  * TensorFlowOnSpark\n  \n__Transfer Learning__ (E.g., Neural Net as Featurizer + Spark Classifier)\n  * Databricks - Spark Deep Learning Pipelines\n  * Microsoft - MMLSpark\n  \n__Bulk Inference in Spark__\n  * All of the above  ","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676143615,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"40a8b2cc-e909-4c96-b61b-dd844e3513dd"},{"version":"CommandV1","origId":1996067380363801,"guid":"71e17ea9-bb5b-4def-895a-61085772806d","subtype":"command","commandType":"auto","position":146.9375,"command":"%md #### What About Fast Prediction on Just a Few Vectors?\n\nFor low-latency (< ~500ms) inference on one or a small set of vectors, you may want to look at complementary tools.\n\nLibraries can take a Spark pipeline or model and allow it to be deployed outside of Spark in a lightweight scale-out service:\n* Databricks \"dbml-local\" (Databricks customers, common ML models)\n* MLeap (http://mleap-docs.combust.ml/)\n  * See my end-to-end demo/tutorial + extra resources at https://www.youtube.com/watch?v=KOehXxEgXFM\n* a few other players...","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676143740,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b747ff8f-35ec-446a-bd76-dfeae8aab2f2"},{"version":"CommandV1","origId":1996067380363802,"guid":"6283d846-fc7e-41ba-b01e-589140b8f63f","subtype":"command","commandType":"auto","position":146.96875,"command":"%md #### And What's New for ML in 2.3?\n\n* Proper Image Data Type for binary/images in DataFrames: https://issues.apache.org/jira/browse/SPARK-21866\n* Linear regression with Huber M-Estimation: https://issues.apache.org/jira/browse/SPARK-3181\n* Improvements to GradientBoostedTree algorithms\n* Ability to create custom pipeline stages from Python (*fairly limited* for now but a first step)\n* FeatureHasher http://spark.apache.org/docs/latest/ml-features.html#featurehasher \n  * Due to much great work by IBM's Nick Pentreath - https://www.linkedin.com/in/mlnick/\n","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"9c6e6695-4c2c-4055-9bcb-61d2fc06ebe9"},{"version":"CommandV1","origId":1996067380363803,"guid":"c872d0ed-f4f8-472b-9bfd-81ffa383efca","subtype":"command","commandType":"auto","position":147.0,"command":"%md ##Structured Streaming\n\nApache Spark Structured Streaming is now production ready! Let's use it to take a look at live Wikipedia edits.\n\nWe can read them in JSON structures from a server/port:","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516676143876,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"591b7ed6-fb12-43ee-a524-e589ced7ecde"},{"version":"CommandV1","origId":1996067380363804,"guid":"058c0e93-121c-4ba8-8c89-cd98db7169c8","subtype":"command","commandType":"auto","position":148.0,"command":"%sh timeout 1 nc 54.213.33.240 9002","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516731285901,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ae15c156-b75e-4d84-b9e8-c8a214596850"},{"version":"CommandV1","origId":1996067380363805,"guid":"0c6cb74d-c994-410d-880b-0b2e3db20650","subtype":"command","commandType":"auto","position":149.0,"command":"%sql SET spark.sql.shuffle.partitions = 3 \n-- fewer tasks for small volume stream","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516731290196,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"cd2036c1-5d47-499d-9bb7-6e576c579bdb"},{"version":"CommandV1","origId":1996067380363806,"guid":"fee2abf5-09af-4028-a166-15d64ab9f5fd","subtype":"command","commandType":"auto","position":150.0,"command":"import org.apache.spark.sql.functions._\nimport org.apache.spark.sql.streaming._\nimport spark.implicits._","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1519716299875,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"9bfdfa18-c90b-4526-a8ce-5853a6647193"},{"version":"CommandV1","origId":1996067380363807,"guid":"2a6af49d-257a-4ad9-b325-1b5e9adaa1f9","subtype":"command","commandType":"auto","position":152.0,"command":"val lines = spark.readStream\n  .format(\"socket\")\n  .option(\"host\", \"54.213.33.240\")\n  .option(\"port\", 9002)\n  .load()\n\nval edits = lines.select(json_tuple('value, \"channel\", \"timestamp\", \"isRobot\", \"isAnonymous\"))","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516731294729,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"934b87f2-ba06-477d-9d7f-82887058b9d6"},{"version":"CommandV1","origId":1996067380363808,"guid":"757eead4-922d-49a3-997f-4b0e44c22bde","subtype":"command","commandType":"auto","position":155.0,"command":"display(edits)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516731295218,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f86a49fa-3ecb-441f-9353-3567335b4c0b"},{"version":"CommandV1","origId":1996067380363809,"guid":"c6b6c95c-378e-4001-a3e5-b63ad7960fa4","subtype":"command","commandType":"auto","position":161.0,"command":"%md We'll try something a little more complex.\n\n* Rename the columns something more useful than c0, c1, etc.\n* Interpret the time as SQL timestamp (it was a raw string earlier)\n* Create 10-second windows over the timestamp\n* Transform the stream by grouping by channel and time, then counting edits","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1509759835037,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2b888daf-7107-423a-bc87-7bcaa40b488c"},{"version":"CommandV1","origId":1996067380363810,"guid":"57480f23-146d-4c74-85cb-9001a6219a4d","subtype":"command","commandType":"auto","position":162.0,"command":"val lines = spark.readStream.format(\"socket\").option(\"host\", \"54.213.33.240\").option(\"port\", 9002).load()\n\nval edits = lines\n                .select(json_tuple('value, \"channel\", \"timestamp\", \"page\"))\n                .selectExpr(\"c0 as channel\", \"cast(c1 as timestamp) as time\", \"c2 as page\")\n                .createOrReplaceTempView(\"edits\")\n\nval editCounts = spark.sql(\"\"\"SELECT count(*), channel, date_format(window(time, '10 seconds').start, 'HH:mm:ss') as time \n                              FROM edits \n                              GROUP BY channel, window(time, '10 seconds')\n                              ORDER BY time\"\"\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516731334108,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1850538b-9ab1-4ab5-9aea-68f218b4c2fa"},{"version":"CommandV1","origId":1996067380363811,"guid":"92d3830b-c914-4e1f-b61f-24a090f7231f","subtype":"command","commandType":"auto","position":163.0,"command":"display(editCounts)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516731338365,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"1222","height":"369","xColumns":["time"],"yColumns":["count(1)"],"pivotColumns":["channel"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ee1f9d65-d06f-4ca5-b256-4d5570ce2d80"},{"version":"CommandV1","origId":1996067380363812,"guid":"d5eb6cca-1f87-4c6f-8b80-732bfd8d9a1b","subtype":"command","commandType":"auto","position":165.0,"command":"%md There's a lot of magic going on in that example!\n\nConsider what happens when a record comes in late ... meaning it has a timestamp from a few seconds earlier.\n\nThe `GROUP BY` means that this data needs to be aggregated with the *previously received records having a corresponding timestamp*\n\nIn other words, the data need to be processed based on their indicated order not their received order, and that means *changing an aggregation that was already reported to the output sink*\n\nThe important takeaways in this overview are that\n\n* Spark is designed to do exactly this, and to do it in an optimized and fault-tolerant fashion\n* The performance or suitability of this approach depends on where the data needs to go (the sink)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1509759835087,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e434a145-6761-43b2-a28f-557a05d2cd50"},{"version":"CommandV1","origId":1996067380363813,"guid":"62a5fa21-e16e-4920-9929-fca6ccc6b35e","subtype":"command","commandType":"auto","position":173.0,"command":"%md #####What do we need to do to leverage the most powerful included features in a production environment?\nE.g.,\n* Fault tolerance\n* Available source/sink strategies\n* Incremental query optimization\n\nhttps://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html\n\nAdding a library to Spark on Databricks is easy -- start with Create -> Library in the file GUI. We can look for `spark-sql-kafka-*` ... although in our current Databricks environment, Structured Streaming Kafka access is preloaded.","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1509759835106,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"22f61837-aea4-4ffb-9791-5f9846fe9729"},{"version":"CommandV1","origId":1996067380363814,"guid":"fafc66d1-6f97-48ca-9dd6-08301b92ddf4","subtype":"command","commandType":"auto","position":174.0,"command":"// Reading from Kafka returns a DataFrame with the following fields:\n//\n// key           - data key (i.e., for key-value records; we aren't using it here)\n// value         - data, in base64 encoded binary format. This is our JSON payload. We'll need to cast it to STRING.\n// topic         - Kafka topic. In this case, the topic is the same as the \"wikipedia\" field, so we don't need it.\n// partition     - Kafka topic partition. This server only has one partition, so we don't need this information.\n// offset        - Kafka topic-partition offset value -- this is essentially the message's unique ID. Take a look at the values Kafka produces here!\n// timestamp     - not used\n// timestampType - not used\n\nval kafkaDF = spark.readStream\n  .format(\"kafka\")\n  .option(\"kafka.bootstrap.servers\", \"54.213.33.240:9092\")\n  .option(\"subscribe\", \"en,ru,zh,pl,de\")\n  .load()\n\nval editsDF = kafkaDF.select($\"value\".cast(\"string\").as(\"value\"))","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1521413230094,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"32d2c6e8-e688-4c46-b39f-bb9c5ec453a1"},{"version":"CommandV1","origId":1996067380363815,"guid":"eaee4657-c438-44ad-8d3b-0b4926f8fbc9","subtype":"command","commandType":"auto","position":177.0,"command":"display(editsDF)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1519716308234,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7adc5955-9cd3-4129-b033-ca9a62b33162"},{"version":"CommandV1","origId":1996067380363816,"guid":"9de92cb6-d405-4a36-8e79-d4efe7e7ec6d","subtype":"command","commandType":"auto","position":178.0,"command":"import org.apache.spark.sql.types._\nimport org.apache.spark.sql.functions._\n\n/*\nval schema = StructType(List(\n                StructField(\"wikipedia\", StringType, false),\n                StructField(\"timestamp\", TimestampType, false),\n                StructField(\"page\", StringType, false),\n                StructField(\"isRobot\", BooleanType, false)\n             ))\n\n -- NOPE! You can do this, but now you don't have to!\n*/\n\nval schema = StructType.fromDDL(\"wikipedia STRING, timestamp TIMESTAMP, page STRING, isRobot BOOLEAN\")\n\nval extractedDF = editsDF.select(from_json('value, schema) as \"json\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1521413496041,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1ad67178-a7c1-458c-8424-7f3804065b93"},{"version":"CommandV1","origId":1996067380363817,"guid":"d4909402-cda6-4164-a7c4-de4ea05c91be","subtype":"command","commandType":"auto","position":178.25,"command":"display(extractedDF)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1521413523710,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"64494e00-6ffa-4483-9904-f221b47e4199"},{"version":"CommandV1","origId":1996067380363818,"guid":"ae30598c-d85f-4f05-98a1-cdebfe1972f8","subtype":"command","commandType":"auto","position":178.5,"command":"extractedDF.printSchema","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516731417316,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"270f2a24-e0be-44a9-9597-72fe39c258cf"},{"version":"CommandV1","origId":1996067380363819,"guid":"f05427c3-92c6-4cdd-a958-d04bb125f767","subtype":"command","commandType":"auto","position":182.0,"command":"val windowColDF = extractedDF.select($\"json.wikipedia\", window($\"json.timestamp\", \"10 seconds\") as \"time\", $\"json.page\", $\"json.isRobot\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516731419466,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"379faf3d-2c4b-4e86-a902-b8683bf84497"},{"version":"CommandV1","origId":1996067380363820,"guid":"919699ee-0563-4d80-91d4-9a694bacfac4","subtype":"command","commandType":"auto","position":183.0,"command":"val prettyView = windowColDF.groupBy('time, 'wikipedia)\n                            .count()\n                            .withColumn(\"period\", date_format($\"time.start\", \"HH:mm:ss\"))\n                            .orderBy(\"period\", \"wikipedia\")\n\ndisplay(prettyView)","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516731421749,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"1043","height":"389","xColumns":["period"],"yColumns":["count"],"pivotColumns":["wikipedia"],"pivotAggregation":"sum","customPlotOptions":{"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1252bd8e-056f-45de-98a8-283d90376893"},{"version":"CommandV1","origId":1996067380363821,"guid":"270633e2-4752-48da-98b9-c3c6b639225b","subtype":"command","commandType":"auto","position":184.0,"command":"dbutils.fs.rm(\"/tmp/demo\", true)\ndbutils.fs.rm(\"/tmp/ck\", true)\n\nval query = windowColDF.writeStream\n  .option(\"checkpointLocation\", \"/tmp/ck\")\n  .format(\"parquet\")\n  .start(\"/tmp/demo\")","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516731468931,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d6ae67a6-9aaa-482c-b682-7d33ea9597fa"},{"version":"CommandV1","origId":1996067380363822,"guid":"ccac31fc-5d67-4aef-8fd1-bbd55cb9992a","subtype":"command","commandType":"auto","position":184.5,"command":"val prettyView = spark.read.parquet(\"/tmp/demo\")\n                            .groupBy('time, 'wikipedia)\n                            .count()\n                            .withColumn(\"time_interval\", date_format($\"time.start\", \"HH:mm:ss\"))\n                            .orderBy(\"time_interval\", \"wikipedia\")\n\ndisplay(prettyView)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516731594568,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"875","height":"340","xColumns":["time_interval"],"yColumns":["count"],"pivotColumns":["wikipedia"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5a12c794-c609-4dc3-a98d-03be38716c6b"},{"version":"CommandV1","origId":1996067380363823,"guid":"351bfd4b-02c9-4205-92ae-522bb6354e20","subtype":"command","commandType":"auto","position":186.0,"command":"%md This is the modern way to use Spark streaming, making continuous applications much easier to engineer and more flexible toward changing business requirements.","commandVersion":1,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1509759835246,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8fe97baa-0505-4450-a748-134c96dbe8b1"},{"version":"CommandV1","origId":1996067380363824,"guid":"66f5b30e-777a-4260-b7eb-215c310a6866","subtype":"command","commandType":"auto","position":187.0,"command":"query.stop","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1516731658113,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e5eefc8d-a20c-45ac-9011-cacb90cc9c92"},{"version":"CommandV1","origId":1996067380363825,"guid":"6676facf-3752-4c86-ac41-c092ac1d2c61","subtype":"command","commandType":"auto","position":187.5,"command":"%md #### Spark 2.3: Continuous Streaming with Millisecond Latency\n\n<img src=\"https://i.imgur.com/5ABtu2C.png\" width=800>\n\nSpark 2.3 also adds stream-stream join support, critical in advertising and financial applications among others.\n\nRead more about continuous-mode streaming in this blog:\n\nhttps://databricks.com/blog/2018/03/20/low-latency-continuous-processing-mode-in-structured-streaming-in-apache-spark-2-3-0.html","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6752dbb7-1f68-44c0-b029-e86099360807"},{"version":"CommandV1","origId":1996067380363826,"guid":"4d83da0f-a9d9-447f-9e54-1c624d206366","subtype":"command","commandType":"auto","position":188.0,"command":"%md ### Where to learn more?\n\nThere's lots of material out there -- make sure you're learning about __modern Spark (2.x)__ and modern best practices!\n\nLuckily, we now have those books starting to come out:\n\n<table style=\"border:none\"><tr><td style=\"border:none\">\n<img src=\"https://i.imgur.com/LwLmsvX.png\" width=300>\n<img src=\"https://i.imgur.com/PRMBvHu.png\" width=300>\n<img src=\"https://i.imgur.com/AkmQ5az.png\" width=300>\n</td></tr></table>","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1509759835277,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1802468a-8e8a-4b07-8afc-e257071edc89"}],"dashboards":[{"version":"DashboardViewV1","origId":1996067380363828,"guid":"a361c602-b49d-48b6-9a2f-974192ed7543","nuid":"fdd4535e-0af2-4854-a840-88d11ed2788a","title":"Wikipedia Activity","width":1024,"layoutOption":{"stack":true,"grid":true},"elements":[],"globalVars":{}}],"guid":"0c957c11-8c0f-4316-8051-e305887835b1","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/js/metrics-graphics.js"
 onerror="window.mainJsLoadError = true;"></script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/5831ae89d3a928d5ef370e1915c5e9d8f2680c0aeaf42f6ff3f3e74e4d3453b8/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>
